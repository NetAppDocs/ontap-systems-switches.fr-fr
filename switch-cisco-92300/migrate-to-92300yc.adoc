---
permalink: switch-cisco-92300/migrate-to-92300yc.html 
sidebar: sidebar 
keywords: migration steps for cisco nexus 92300yc cluster switch 
summary: 'Vous pouvez migrer d"anciens commutateurs de cluster Cisco sans interruption pour un cluster ONTAP vers des commutateurs de réseau de cluster Cisco Nexus 92300YC.' 
---
= Migration d'un commutateur Cisco vers un commutateur Cisco Nexus 92300YC
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Vous pouvez migrer d'anciens commutateurs de cluster Cisco sans interruption pour un cluster ONTAP vers des commutateurs de réseau de cluster Cisco Nexus 92300YC.


NOTE: Une fois la migration terminée, vous devrez peut-être installer le fichier de configuration requis pour prendre en charge le Cluster Switch Health Monitor (CSHM) pour les commutateurs de cluster 92300YC. Voirlink:setup-install-cshm-file.html["Installer le moniteur d'intégrité du commutateur de cluster (CSHM)"].



== Examen des conditions requises

.Ce dont vous avez besoin
* Un cluster existant entièrement fonctionnel.
* Connectivité 10 GbE et 40 GbE des nœuds aux commutateurs de cluster Nexus 92300YC.
* Tous les ports du cluster sont à l'état up pour assurer la continuité de l'activité.
* Version appropriée du système d'exploitation NX-OS et du fichier RCF (Reference Configuration File) installés sur les commutateurs de cluster Nexus 92300YC.
* Un cluster NetApp redondant et entièrement fonctionnel utilisant les deux anciens commutateurs Cisco.
* Connectivité de gestion et accès à la console aux anciens commutateurs Cisco et aux nouveaux commutateurs.
* Toutes les LIFs de cluster à l'état up avec les LIFs de cluster sont sur leurs ports de type home.
* Ports ISL activés et câblés entre les anciens commutateurs Cisco et entre les nouveaux commutateurs.




== Migrer le commutateur

.À propos des exemples
Les exemples de cette procédure utilisent la nomenclature des commutateurs et des nœuds suivante :

* Les commutateurs de cluster Cisco Nexus 5596UP existants sont c1 et c2.
* Les nouveaux commutateurs de cluster Nexus 92300YC sont cs1 et cs2.
* Les nœuds sont les nœuds 1 et 2.
* Les LIF de cluster sont respectivement node1_clude1 et node1_clus2 sur le nœud 1, et node2_concluA1 et node2_clus2 sur le nœud 2.
* Le contacteur c2 est d'abord remplacé par le contacteur cs2, puis le contacteur c1 est remplacé par le contacteur cs1.
+
** Un ISL temporaire est construit sur cs1 qui connecte c1 à cs1.
** Le câblage entre les nœuds et c2 est ensuite déconnecté de c2 et reconnecté à cs2.
** Le câblage entre les nœuds et c1 est ensuite déconnecté de c1 et reconnecté à cs1.
** L'ISL temporaire entre c1 et cs1 est alors supprimé.




.Ports utilisés pour les connexions
* Certains ports sont configurés sur les commutateurs Nexus 92300YC pour fonctionner à 10 GbE ou 40 GbE.
* Les commutateurs de cluster utilisent les ports suivants pour les connexions aux nœuds :
+
** Ports e1/1-48 (10/25 GbE), e1/49-64 (40/100 GbE) : Nexus 92300YC
** Ports e1/1-40 (10 GbE) : Nexus 5596UP
** Ports e1/1-32 (10 GbE) : Nexus 5020
** Ports e1/1-12, e2/1-6 (10 GbE) : Nexus 5010 avec module d'extension


* Les commutateurs de cluster utilisent les ports ISL (Inter-Switch Link) suivants :
+
** Ports e1/65-66 (100 GbE) : Nexus 92300YC
** Ports e1/41-48 (10 GbE) : Nexus 5596UP
** Ports e1/33-40 (10 GbE) : Nexus 5020
** Ports e1/13-20 (10 GbE) : Nexus 5010


* https://hwu.netapp.com/SWITCH/INDEX["Hardware Universe - commutateurs"^] le contient des informations sur le câblage pris en charge pour tous les commutateurs de cluster.
* Les versions ONTAP et NX-OS prises en charge dans cette procédure se trouvent sur le https://support.netapp.com/NOW/download/software/cm_switches/["Commutateurs Ethernet Cisco"^] page.




=== Étape 1 : préparer la migration

. Définissez le niveau de privilège sur avancé, en entrant *y* lorsque vous êtes invité à continuer :
+
`set -privilege advanced`

+
L'invite avancée (*>) apparaît.

. Si AutoSupport est activé sur ce cluster, supprimez la création automatique de dossiers en invoquant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
où x représente la durée de la fenêtre de maintenance en heures.

+

NOTE: Le message AutoSupport informe le support technique de cette tâche de maintenance de sorte que la création automatique de dossier soit supprimée lors de la fenêtre de maintenance.

+
.Montrer l'exemple
[%collapsible]
====
La commande suivante supprime la création automatique de dossiers pendant deux heures :

[listing, subs="+quotes"]
----
cluster1::*> *system node autosupport invoke -node * -type all -message MAINT=2h*
----
====
. Vérifiez que la fonction de restauration automatique est activée sur l'ensemble des LIFs du cluster :
+
`network interface show -vserver Cluster -fields auto-revert`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster -fields auto-revert*

          Logical
Vserver   Interface     Auto-revert
--------- ------------- ------------
Cluster
          node1_clus1   true
          node1_clus2   true
          node2_clus1   true
          node2_clus2   true

4 entries were displayed.
----
====
. Déterminer le statut administratif ou opérationnel pour chaque interface de cluster :
+
Chaque port doit s'afficher pendant `Link` et en bonne santé pour `Health Status`.

+
.. Afficher les attributs des ports réseau :
+
`network port show -ipspace Cluster`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

4 entries were displayed.
----
====
.. Afficher des informations sur les interfaces logiques et les nœuds home désignés :
+
`network interface show -vserver Cluster`

+
Chaque LIF doit afficher son contenu pendant `Status Admin/Oper` et vrai pour `Is Home`.

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical      Status     Network            Current       Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node          Port    Home
----------- -----------  ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up      169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up      169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up      169.254.19.183/16  node2         e0b     true

4 entries were displayed.
----
====


. Vérifier que les ports de cluster de chaque nœud sont connectés aux commutateurs de cluster existants de la manière suivante (du point de vue des nœuds) à l'aide de la commande :
+
`network device-discovery show -protocol cdp`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    c1                        0/2               N5K-C5596UP
            e0b    c2                        0/2               N5K-C5596UP
node1      /cdp
            e0a    c1                        0/1               N5K-C5596UP
            e0b    c2                        0/1               N5K-C5596UP

4 entries were displayed.
----
====
. Vérifier que les ports et les commutateurs du cluster sont connectés de la manière suivante (du point de vue des switchs) à l'aide de la commande :
+
`show cdp neighbors`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
c1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute


Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1               Eth1/1         124    H         FAS2750            e0a
node2               Eth1/2         124    H         FAS2750            e0a
c2(FOX2025GEFC)     Eth1/41        179    S I s     N5K-C5596UP        Eth1/41

c2(FOX2025GEFC)     Eth1/42        175    S I s     N5K-C5596UP        Eth1/42

c2(FOX2025GEFC)     Eth1/43        179    S I s     N5K-C5596UP        Eth1/43

c2(FOX2025GEFC)     Eth1/44        175    S I s     N5K-C5596UP        Eth1/44

c2(FOX2025GEFC)     Eth1/45        179    S I s     N5K-C5596UP        Eth1/45

c2(FOX2025GEFC)     Eth1/46        179    S I s     N5K-C5596UP        Eth1/46

c2(FOX2025GEFC)     Eth1/47        175    S I s     N5K-C5596UP        Eth1/47

c2(FOX2025GEFC)     Eth1/48        179    S I s     N5K-C5596UP        Eth1/48

Total entries displayed: 10


c2# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute


Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1               Eth1/1         124    H         FAS2750            e0b
node2               Eth1/2         124    H         FAS2750            e0b
c1(FOX2025GEEX)     Eth1/41        175    S I s     N5K-C5596UP        Eth1/41

c1(FOX2025GEEX)     Eth1/42        175    S I s     N5K-C5596UP        Eth1/42

c1(FOX2025GEEX)     Eth1/43        175    S I s     N5K-C5596UP        Eth1/43

c1(FOX2025GEEX)     Eth1/44        175    S I s     N5K-C5596UP        Eth1/44

c1(FOX2025GEEX)     Eth1/45        175    S I s     N5K-C5596UP        Eth1/45

c1(FOX2025GEEX)     Eth1/46        175    S I s     N5K-C5596UP        Eth1/46

c1(FOX2025GEEX)     Eth1/47        176    S I s     N5K-C5596UP        Eth1/47

c1(FOX2025GEEX)     Eth1/48        176    S I s     N5K-C5596UP        Eth1/48
----
====
. Vérifiez que le réseau en cluster dispose d'une connectivité complète via la commande :
+
`cluster ping-cluster -node node-name`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node node2*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1     e0a
Cluster node1_clus2 169.254.49.125 node1     e0b
Cluster node2_clus1 169.254.47.194 node2     e0a
Cluster node2_clus2 169.254.19.183 node2     e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
====




=== Étape 2 : configurer les câbles et les ports

. Configurez un lien ISL temporaire sur les ports E1/41-48, entre c1 et cs1.
+
.Montrer l'exemple
[%collapsible]
====
L'exemple suivant montre comment le nouveau ISL est configuré sur c1 et cs1 :

[listing, subs="+quotes"]
----
cs1# *configure*
Enter configuration commands, one per line. End with CNTL/Z.
cs1(config)# *interface e1/41-48*
cs1(config-if-range)# *description temporary ISL between Nexus 5596UP and Nexus 92300YC*
cs1(config-if-range)# *no lldp transmit*
cs1(config-if-range)# *no lldp receive*
cs1(config-if-range)# *switchport mode trunk*
cs1(config-if-range)# *no spanning-tree bpduguard enable*
cs1(config-if-range)# *channel-group 101 mode active*
cs1(config-if-range)# *exit*
cs1(config)# *interface port-channel 101*
cs1(config-if)# *switchport mode trunk*
cs1(config-if)# *spanning-tree port type network*
cs1(config-if)# *exit*
cs1(config)# *exit*
----
====
. Retirez les câbles ISL des ports e1/41-48 de c2 et connectez les câbles aux ports e1/41-48 de cs1.
. Vérifiez que les ports ISL et le canal de port fonctionnent en connectant c1 et cs1 :
+
`show port-channel summary`

+
.Montrer l'exemple
[%collapsible]
====
L'exemple suivant montre la commande Cisco show port-Channel Summary utilisée pour vérifier que les ports ISL sont opérationnels sur c1 et cs1 :

[listing, subs="+quotes"]
----
c1# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/41(P)   Eth1/42(P)   Eth1/43(P)
                                     Eth1/44(P)   Eth1/45(P)   Eth1/46(P)
                                     Eth1/47(P)   Eth1/48(P)


cs1# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/65(P)   Eth1/66(P)
101   Po101(SU)   Eth      LACP      Eth1/41(P)   Eth1/42(P)   Eth1/43(P)
                                     Eth1/44(P)   Eth1/45(P)   Eth1/46(P)
                                     Eth1/47(P)   Eth1/48(P)
----
====
. Pour le nœud1, déconnectez le câble de e1/1 sur c2, puis connectez le câble à e1/1 sur cs2, à l'aide du câblage approprié pris en charge par le commutateur Nexus 92300YC.
. Pour le nœud2, déconnectez le câble de e1/2 sur c2, puis connectez le câble à e1/2 sur cs2, à l'aide du câblage approprié pris en charge par le commutateur Nexus 92300YC.
. Les ports de cluster de chaque nœud sont désormais connectés aux commutateurs de cluster de la façon suivante, du point de vue des nœuds :
+
`network device-discovery show -protocol cdp`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    c1                        0/2               N5K-C5596UP
            e0b    cs2                       0/2               N9K-C92300YC
node1      /cdp
            e0a    c1                        0/1               N5K-C5596UP
            e0b    cs2                       0/1               N9K-C92300YC

4 entries were displayed.
----
====
. Pour le nœud1, déconnectez le câble de e1/1 sur c1, puis connectez le câble à e1/1 sur cs1, à l'aide du câblage approprié pris en charge par le commutateur Nexus 92300YC.
. Pour le nœud2, déconnectez le câble de e1/2 sur c1, puis connectez le câble à e1/2 sur cs1, à l'aide du câblage approprié pris en charge par le commutateur Nexus 92300YC.
. Les ports de cluster de chaque nœud sont désormais connectés aux commutateurs de cluster de la façon suivante, du point de vue des nœuds :
+
`network device-discovery show -protocol cdp`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       0/2               N9K-C92300YC
            e0b    cs2                       0/2               N9K-C92300YC
node1      /cdp
            e0a    cs1                       0/1               N9K-C92300YC
            e0b    cs2                       0/1               N9K-C92300YC
4 entries were displayed.
----
====
. Supprimez l'ISL temporaire entre cs1 et c1.
+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1(config)# *no interface port-channel 10*
cs1(config)# *interface e1/41-48*
cs1(config-if-range)# *lldp transmit*
cs1(config-if-range)# *lldp receive*
cs1(config-if-range)# *no switchport mode trunk*
cs1(config-if-range)# *no channel-group*
cs1(config-if-range)# *description 10GbE Node Port*
cs1(config-if-range)# *spanning-tree bpduguard enable*
cs1(config-if-range)# *exit*
cs1(config)# *exit*
----
====




=== Étape 3 : terminer la migration

. Vérifier la configuration finale du cluster :
+
`network port show -ipspace Cluster`

+
Chaque port doit s'afficher pendant `Link` et en bonne santé pour `Health Status`.

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

4 entries were displayed.


cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e0b     true

4 entries were displayed.


cluster1::*> *network device-discovery show -protocol cdp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       0/2               N9K-C92300YC
            e0b    cs2                       0/2               N9K-C92300YC
node1      /cdp
            e0a    cs1                       0/1               N9K-C92300YC
            e0b    cs2                       0/1               N9K-C92300YC

4 entries were displayed.


cs1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1               Eth1/1         124    H         FAS2750            e0a
node2               Eth1/2         124    H         FAS2750            e0a
cs2(FDO220329V5)    Eth1/65        179    R S I s   N9K-C92300YC  Eth1/65
cs2(FDO220329V5)    Eth1/66        179    R S I s   N9K-C92300YC  Eth1/66


cs2# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1               Eth1/1         124    H         FAS2750            e0b
node2               Eth1/2         124    H         FAS2750            e0b
cs1(FDO220329KU)
                    Eth1/65        179    R S I s   N9K-C92300YC  Eth1/65
cs1(FDO220329KU)
                    Eth1/66        179    R S I s   N9K-C92300YC  Eth1/66

Total entries displayed: 4
----
====
. Vérifiez que le réseau de cluster dispose d'une connectivité complète :
+
`cluster ping-cluster -node node-name`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *set -priv advanced*

Warning: These advanced commands are potentially dangerous; use them only when
         directed to do so by NetApp personnel.
Do you want to continue? {y|n}: *y*

cluster1::*> *cluster ping-cluster -node node2*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1     e0a
Cluster node1_clus2 169.254.49.125 node1     e0b
Cluster node2_clus1 169.254.47.194 node2     e0a
Cluster node2_clus2 169.254.19.183 node2     e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)


cluster1::*> *set -privilege admin*
cluster1::*>
----
====
. Pour ONTAP 9.4 et versions ultérieures, activez la fonctionnalité de collecte des journaux du contrôle de l'état du commutateur de cluster pour collecter les fichiers journaux des commutateurs, à l'aide des commandes :
+
`system cluster-switch log setup-password` et `system cluster-switch log enable-collection`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system cluster-switch log setup-password*
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
cs1
cs2

cluster1::*> *system cluster-switch log setup-password*

Enter the switch name: *cs1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> *system cluster-switch log setup-password*

Enter the switch name: *cs2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> *system cluster-switch log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
====
+

NOTE: Si l'une de ces commandes renvoie une erreur, contactez le support NetApp.


