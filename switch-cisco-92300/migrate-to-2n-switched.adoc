---
permalink: switch-cisco-92300/migrate-to-2n-switched.html 
sidebar: sidebar 
keywords: 2-node switched Cisco 92300YC cluster switch migration 
summary: 'Si vous disposez déjà d"un environnement de cluster sans commutateur à deux nœuds, vous pouvez migrer vers un environnement de cluster commuté à deux nœuds à l"aide de commutateurs Cisco Nexus 92300YC pour vous permettre d"évoluer au-delà de deux nœuds dans le cluster.' 
---
= Migrer vers un cluster commuté à deux nœuds avec un commutateur Cisco Nexus 92300YC
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Si vous disposez d'un environnement de cluster existant à deux nœuds _sans commutateur_, vous pouvez migrer vers un environnement de cluster à deux nœuds _commuté_ en utilisant des commutateurs Cisco Nexus 92300YC pour vous permettre d'évoluer au-delà de deux nœuds dans le cluster.

La procédure à suivre dépend du fait que chaque contrôleur dispose de deux ports réseau de cluster dédiés ou d'un seul port de cluster par contrôleur.  Le processus décrit fonctionne pour tous les nœuds utilisant des ports optiques ou twinax, mais n'est pas pris en charge sur ce commutateur si les nœuds utilisent des ports RJ45 10Gb BASE-T intégrés pour les ports du réseau de cluster.

La plupart des systèmes nécessitent deux ports réseau dédiés au cluster sur chaque contrôleur.


NOTE: Une fois votre migration terminée, vous devrez peut-être installer le fichier de configuration requis pour prendre en charge le moniteur d'intégrité du commutateur de cluster (CSHM) pour les commutateurs de cluster 92300YC. Voirlink:../switch-cshm/cshm-overview.html["Surveillance de l'état des commutateurs (CSHM)"] .



== Exigences de révision

.Avant de commencer
Assurez-vous d'avoir les éléments suivants :

Pour une configuration sans commutateur à deux nœuds, assurez-vous que :

* La configuration sans commutateur à deux nœuds est correctement mise en place et fonctionne.
* Les nœuds exécutent ONTAP 9.6 et versions ultérieures.
* Tous les ports du cluster sont en état de fonctionnement.
* Toutes les interfaces logiques du cluster (LIF) sont à l'état *actif* et sur leurs ports d'origine.


Pour la configuration du commutateur Cisco Nexus 92300YC :

* Les deux commutateurs disposent d'une connectivité au réseau de gestion.
* Il existe un accès console aux commutateurs du cluster.
* Les connexions de nœud à nœud et de commutateur à commutateur du Nexus 92300YC utilisent des câbles twinax ou à fibre optique.
+
https://hwu.netapp.com/SWITCH/INDEX["Hardware Universe - Commutateurs"^]Contient plus d'informations sur le câblage.

* Les câbles Inter-Switch Link (ISL) sont connectés aux ports 1/65 et 1/66 sur les deux commutateurs 92300YC.
* La personnalisation initiale des deux commutateurs 92300YC est terminée.  Afin que :
+
** Les commutateurs 92300YC exécutent la dernière version du logiciel
** Les fichiers de configuration de référence (RCF) sont appliqués aux commutateurs. Toute personnalisation du site, telle que SMTP, SNMP et SSH, est configurée sur les nouveaux commutateurs.






== Déplacer le commutateur

.À propos des exemples
Les exemples de cette procédure utilisent la nomenclature suivante pour les commutateurs de cluster et les nœuds :

* Les noms des commutateurs 92300YC sont cs1 et cs2.
* Les noms des SVM du cluster sont node1 et node2.
* Les noms des LIF sont node1_clus1 et node1_clus2 sur le nœud 1, et node2_clus1 et node2_clus2 sur le nœud 2 respectivement.
* Le `cluster1::*>` L'invite indique le nom du cluster.
* Les ports du cluster utilisés dans cette procédure sont e0a et e0b.
+
https://hwu.netapp.com["Hardware Universe"^]Contient les informations les plus récentes concernant les ports de cluster actuels pour vos plateformes.





=== Étape 1 : Préparer la migration

. Modifiez le niveau de privilège en avancé, puis saisissez `y` lorsqu'on vous invite à continuer :
+
`set -privilege advanced`

+
L'invite avancée(`*>` ) apparaît.

. Si AutoSupport est activé sur ce cluster, supprimez la création automatique de cas en envoyant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
où x représente la durée de la fenêtre de maintenance en heures.

+

NOTE: Le message AutoSupport notifie le support technique de cette tâche de maintenance afin que la création automatique de tickets soit désactivée pendant la période de maintenance.

+
.Afficher un exemple
[%collapsible]
====
La commande suivante désactive la création automatique de cas pendant deux heures :

[listing, subs="+quotes"]
----
cluster1::*> *system node autosupport invoke -node * -type all -message MAINT=2h*
----
====




=== Étape 2 : Configurer les câbles et les ports

. Désactivez tous les ports orientés vers les nœuds (à l'exception des ports ISL) sur les deux nouveaux commutateurs de cluster cs1 et cs2.
+
Vous ne devez pas désactiver les ports ISL.

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que les ports 1 à 64 orientés vers le nœud sont désactivés sur le commutateur cs1 :

[listing, subs="+quotes"]
----
cs1# *config*
Enter configuration commands, one per line. End with CNTL/Z.
cs1(config)# *interface e/1-64*
cs1(config-if-range)# *shutdown*
----
====
. Vérifiez que l'ISL et les ports physiques sur l'ISL entre les deux commutateurs 92300YC cs1 et cs2 sont actifs sur les ports 1/65 et 1/66 :
+
`show port-channel summary`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que les ports ISL sont opérationnels sur le commutateur cs1 :

[listing, subs="+quotes"]
----
cs1# *show port-channel summary*

Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/65(P)   Eth1/66(P)
----
+ L'exemple suivant montre que les ports ISL sont opérationnels sur le commutateur cs2 :

+

[listing, subs="+quotes"]
----
(cs2)# *show port-channel summary*

Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/65(P)   Eth1/66(P)
----
====
. Afficher la liste des appareils voisins :
+
`show cdp neighbors`

+
Cette commande fournit des informations sur les périphériques connectés au système.

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant répertorie les périphériques voisins sur le commutateur cs1 :

[listing, subs="+quotes"]
----
cs1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
cs2(FDO220329V5)    Eth1/65        175    R S I s   N9K-C92300YC  Eth1/65
cs2(FDO220329V5)    Eth1/66        175    R S I s   N9K-C92300YC  Eth1/66

Total entries displayed: 2
----
+ L'exemple suivant liste les périphériques voisins sur le commutateur cs2 :

+

[listing, subs="+quotes"]
----
cs2# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
cs1(FDO220329KU)    Eth1/65        177    R S I s   N9K-C92300YC  Eth1/65
cs1(FDO220329KU)    Eth1/66        177    R S I s   N9K-C92300YC  Eth1/66

Total entries displayed: 2
----
====
. Vérifiez que tous les ports du cluster sont opérationnels :
+
`network port show -ipspace Cluster`

+
Chaque port devrait s'afficher correctement. `Link` et sain pour `Health Status` .

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1

                                                  Speed(Mbps) Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status
--------- ------------ ---------------- ---- ---- ----------- --------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy
e0b       Cluster      Cluster          up   9000  auto/10000 healthy

Node: node2

                                                  Speed(Mbps) Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status
--------- ------------ ---------------- ---- ---- ----------- --------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy
e0b       Cluster      Cluster          up   9000  auto/10000 healthy

4 entries were displayed.
----
====
. Vérifiez que toutes les interfaces réseau du cluster sont opérationnelles :
+
`network interface show -vserver Cluster`

+
Chaque LIF de cluster doit afficher vrai pour `Is Home` et avoir un `Status Admin/Oper` de haut/haut

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- -----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e0b     true
4 entries were displayed.
----
====
. Vérifiez que la restauration automatique est activée sur toutes les LIF du cluster :
+
`network interface show -vserver Cluster -fields auto-revert`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster -fields auto-revert*

          Logical
Vserver   Interface     Auto-revert
--------- ------------- ------------
Cluster
          node1_clus1   true
          node1_clus2   true
          node2_clus1   true
          node2_clus2   true

4 entries were displayed.
----
====
. Déconnectez le câble du port de cluster e0a sur le nœud 1, puis connectez e0a au port 1 sur le commutateur de cluster cs1, à l'aide du câblage approprié pris en charge par les commutateurs 92300YC.
+
Le https://hwu.netapp.com/SWITCH/INDEX["_Hardware Universe - Commutateurs_"^] Contient plus d'informations sur le câblage.

. Déconnectez le câble du port de cluster e0a sur node2, puis connectez e0a au port 2 sur le commutateur de cluster cs1, à l'aide du câblage approprié pris en charge par les commutateurs 92300YC.
. Activez tous les ports orientés vers les nœuds sur le commutateur de cluster cs1.
+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que les ports 1/1 à 1/64 sont activés sur le commutateur cs1 :

[listing, subs="+quotes"]
----
cs1# *config*
Enter configuration commands, one per line. End with CNTL/Z.
cs1(config)# *interface e1/1-64*
cs1(config-if-range)# *no shutdown*
----
====
. Vérifiez que toutes les LIF du cluster sont opérationnelles et que leur état est correct. `Is Home` :
+
`network interface show -vserver Cluster`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que tous les LIF sont opérationnels sur les nœuds 1 et 2 et que `Is Home` Les résultats sont exacts :

[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

         Logical      Status     Network            Current     Current Is
Vserver  Interface    Admin/Oper Address/Mask       Node        Port    Home
-------- ------------ ---------- ------------------ ----------- ------- ----
Cluster
         node1_clus1  up/up      169.254.209.69/16  node1       e0a     true
         node1_clus2  up/up      169.254.49.125/16  node1       e0b     true
         node2_clus1  up/up      169.254.47.194/16  node2       e0a     true
         node2_clus2  up/up      169.254.19.183/16  node2       e0b     true

4 entries were displayed.
----
====
. Afficher les informations relatives à l'état des nœuds du cluster :
+
`cluster show`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant présente des informations sur l'état et l'éligibilité des nœuds du cluster :

[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Déconnectez le câble du port de cluster e0b sur le nœud 1, puis connectez e0b au port 1 sur le commutateur de cluster cs2, à l'aide du câblage approprié pris en charge par les commutateurs 92300YC.
. Déconnectez le câble du port de cluster e0b sur node2, puis connectez e0b au port 2 sur le commutateur de cluster cs2, à l'aide du câblage approprié pris en charge par les commutateurs 92300YC.
. Activez tous les ports orientés vers les nœuds sur le commutateur de cluster cs2.
+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que les ports 1/1 à 1/64 sont activés sur le commutateur cs2 :

[listing, subs="+quotes"]
----
cs2# *config*
Enter configuration commands, one per line. End with CNTL/Z.
cs2(config)# *interface e1/1-64*
cs2(config-if-range)# *no shutdown*
----
====




=== Étape 3 : Vérifier la configuration

. Vérifiez que tous les ports du cluster sont opérationnels :
+
`network port show -ipspace Cluster`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que tous les ports du cluster sont opérationnels sur les nœuds 1 et 2 :

[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

4 entries were displayed.
----
====
. Vérifiez que toutes les interfaces affichent « vrai » pour `Is Home` :
+
`network interface show -vserver Cluster`

+

NOTE: Cela peut prendre plusieurs minutes.

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que toutes les LIF sont opérationnelles sur les nœuds 1 et 2 et que `Is Home` Les résultats sont exacts :

[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

          Logical      Status     Network            Current    Current Is
Vserver   Interface    Admin/Oper Address/Mask       Node       Port    Home
--------- ------------ ---------- ------------------ ---------- ------- ----
Cluster
          node1_clus1  up/up      169.254.209.69/16  node1      e0a     true
          node1_clus2  up/up      169.254.49.125/16  node1      e0b     true
          node2_clus1  up/up      169.254.47.194/16  node2      e0a     true
          node2_clus2  up/up      169.254.19.183/16  node2      e0b     true

4 entries were displayed.
----
====
. Vérifiez que chaque nœud possède une connexion à chaque commutateur :
+
`show cdp neighbors`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant illustre les résultats attendus pour les deux commutateurs :

[listing, subs="+quotes"]
----
(cs1)# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1               Eth1/1         133    H         FAS2980       e0a
node2               Eth1/2         133    H         FAS2980       e0a
cs2(FDO220329V5)    Eth1/65        175    R S I s   N9K-C92300YC  Eth1/65
cs2(FDO220329V5)    Eth1/66        175    R S I s   N9K-C92300YC  Eth1/66

Total entries displayed: 4


(cs2)# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1               Eth1/1         133    H         FAS2980       e0b
node2               Eth1/2         133    H         FAS2980       e0b
cs1(FDO220329KU)
                    Eth1/65        175    R S I s   N9K-C92300YC  Eth1/65
cs1(FDO220329KU)
                    Eth1/66        175    R S I s   N9K-C92300YC  Eth1/66

Total entries displayed: 4
----
====
. Afficher les informations relatives aux périphériques réseau détectés dans votre cluster :
+
`network device-discovery show -protocol cdp`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       0/2               N9K-C92300YC
            e0b    cs2                       0/2               N9K-C92300YC
node1      /cdp
            e0a    cs1                       0/1               N9K-C92300YC
            e0b    cs2                       0/1               N9K-C92300YC

4 entries were displayed.
----
====
. Vérifiez que les paramètres sont désactivés :
+
`network options switchless-cluster show`

+

NOTE: L'exécution de la commande peut prendre plusieurs minutes.  Attendez l'annonce « Durée de vie restante de 3 minutes ».

+
.Afficher un exemple
[%collapsible]
====
Le résultat erroné de l'exemple suivant indique que les paramètres de configuration sont désactivés :

[listing, subs="+quotes"]
----
cluster1::*> *network options switchless-cluster show*
Enable Switchless Cluster: false
----
====
. Vérifiez l'état des nœuds membres du cluster :
+
`cluster show`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant présente des informations sur l'état et l'éligibilité des nœuds du cluster :

[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  --------
node1                true    true          false
node2                true    true          false
----
====
. Vérifiez la connectivité des interfaces du cluster distant :


[role="tabbed-block"]
====
.ONTAP 9.9.1 et versions ultérieures
--
Vous pouvez utiliser le `network interface check cluster-connectivity` commande permettant de lancer une vérification d'accessibilité pour la connectivité du cluster, puis d'afficher les détails :

`network interface check cluster-connectivity start`et `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*REMARQUE :* Attendez quelques secondes avant d’exécuter le programme. `show` commande pour afficher les détails.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Toutes les versions ONTAP
--
Pour toutes les versions ONTAP , vous pouvez également utiliser `cluster ping-cluster -node <name>` commande pour vérifier la connectivité :

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*

Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:

Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)

Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[étape 8]] Si vous avez désactivé la création automatique de dossiers, réactivez-la en envoyant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system node autosupport invoke -node * -type all -message MAINT=END*
----
====
. Rétablir le niveau de privilège à administrateur :
+
`set -privilege admin`



.Quelle est la prochaine étape ?
link:../switch-cshm/config-overview.html["Configurer la surveillance de l'état du commutateur"].
