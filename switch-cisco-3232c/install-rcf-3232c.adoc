---
permalink: switch-cisco-3232c/install-rcf-3232c.html 
sidebar: sidebar 
keywords: install, rcf 
summary: Vous pouvez installer RCF après avoir configuré le commutateur Nexus 3232C pour la première fois. Vous pouvez également utiliser cette procédure pour mettre à jour votre version de RCF. 
---
= Installer ou mettre à niveau le fichier de configuration de référence (RCF)
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Suivez cette procédure pour installer le RCF après avoir configuré le commutateur Nexus 3232C pour la première fois.

Vous pouvez également utiliser cette procédure pour mettre à niveau votre version RCF. Consultez l'article de la base de connaissances https://kb.netapp.com/onprem/Switches/Cisco/How_to_clear_configuration_on_a_Cisco_interconnect_switch_while_retaining_remote_connectivity["Comment effacer la configuration d'un commutateur d'interconnexion Cisco tout en conservant la connectivité à distance"^] pour plus d'informations lors de la mise à niveau de votre RCF.



== Exigences de révision

.Avant de commencer
* Une sauvegarde actuelle de la configuration du commutateur.
* Un cluster parfaitement fonctionnel (aucune erreur dans les journaux ni problème similaire).
* Le fichier de configuration de référence (RCF) actuel.
* Une connexion console au commutateur est nécessaire lors de l'installation du RCF.
* link:https://mysupport.netapp.com/site/info/cisco-ethernet-switch["page du commutateur Ethernet Cisco"^]Consultez le tableau de compatibilité des commutateurs pour connaître les versions ONTAP et RCF prises en charge.  Notez qu'il peut exister des dépendances entre la syntaxe des commandes dans le RCF et celle des versions de NX-OS.
* link:https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Commutateurs Cisco Nexus série 3000"^]. Consultez les guides logiciels et de mise à niveau appropriés disponibles sur le site Web de Cisco pour obtenir la documentation complète sur les procédures de mise à niveau et de rétrogradation des commutateurs Cisco .




== Installez le fichier

.À propos des exemples
Les exemples de cette procédure utilisent la nomenclature suivante pour les commutateurs et les nœuds :

* Les noms des deux commutateurs Cisco sont : `cs1` et `cs2` .
* Les noms des nœuds sont `cluster1-01` , `cluster1-02` , `cluster1-03` , et `cluster1-04` .
* Les noms LIF du cluster sont `cluster1-01_clus1` , `cluster1-01_clus2` , `cluster1-02_clus1` , `cluster1-02_clus2` , `cluster1-03_clus1` , `cluster1-03_clus2` , `cluster1-04_clus1` , et `cluster1-04_clus2` .
* Le `cluster1::*>` L'invite indique le nom du cluster.


.À propos de cette tâche
La procédure nécessite l'utilisation à la fois des commandes ONTAP et des commandes des commutateurs Cisco Nexus série 3000 ; les commandes ONTAP sont utilisées sauf indication contraire.

Aucune liaison inter-commutateurs opérationnelle (ISL) n'est nécessaire pendant cette procédure. Ceci est intentionnel car les changements de version RCF peuvent affecter temporairement la connectivité ISL. Pour garantir le fonctionnement non perturbateur du cluster, la procédure suivante migre toutes les LIF du cluster vers le commutateur partenaire opérationnel tout en exécutant les étapes sur le commutateur cible.

Assurez-vous de terminer la procédure danslink:prepare-install-cisco-nexus-3232c.html["Préparez-vous à installer NX-OS et RCF"] , puis suivez les étapes ci-dessous.

.Étapes
. Afficher les ports du cluster sur chaque nœud qui sont connectés aux commutateurs du cluster :
+
`network device-discovery show`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  --------
cluster1-01/cdp
            e0a    cs1                       Ethernet1/7       N3K-C3232C
            e0d    cs2                       Ethernet1/7       N3K-C3232C
cluster1-02/cdp
            e0a    cs1                       Ethernet1/8       N3K-C3232C
            e0d    cs2                       Ethernet1/8       N3K-C3232C
cluster1-03/cdp
            e0a    cs1                       Ethernet1/1/1     N3K-C3232C
            e0b    cs2                       Ethernet1/1/1     N3K-C3232C
cluster1-04/cdp
            e0a    cs1                       Ethernet1/1/2     N3K-C3232C
            e0b    cs2                       Ethernet1/1/2     N3K-C3232C
cluster1::*>
----
====
. Vérifiez l'état administratif et opérationnel de chaque port du cluster.
+
.. Vérifiez que tous les ports du cluster sont opérationnels et en bon état :
+
`network port show –role cluster`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -role cluster*

Node: cluster1-01
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false

Node: cluster1-02
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false
8 entries were displayed.

Node: cluster1-03

   Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-04
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false
cluster1::*>
----
====
.. Vérifiez que toutes les interfaces du cluster (LIF) sont connectées au port d'accueil :
+
`network interface show -role cluster`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical            Status     Network           Current      Current Is
Vserver     Interface          Admin/Oper Address/Mask      Node         Port    Home
----------- ------------------ ---------- ----------------- ------------ ------- ----
Cluster
            cluster1-01_clus1  up/up     169.254.3.4/23     cluster1-01  e0a     true
            cluster1-01_clus2  up/up     169.254.3.5/23     cluster1-01  e0d     true
            cluster1-02_clus1  up/up     169.254.3.8/23     cluster1-02  e0a     true
            cluster1-02_clus2  up/up     169.254.3.9/23     cluster1-02  e0d     true
            cluster1-03_clus1  up/up     169.254.1.3/23     cluster1-03  e0a     true
            cluster1-03_clus2  up/up     169.254.1.1/23     cluster1-03  e0b     true
            cluster1-04_clus1  up/up     169.254.1.6/23     cluster1-04  e0a     true
            cluster1-04_clus2  up/up     169.254.1.7/23     cluster1-04  e0b     true
8 entries were displayed.
cluster1::*>
----
====
.. Vérifiez que le cluster affiche les informations pour les deux commutateurs du cluster :
+
`system cluster-switch show -is-monitoring-enabled-operational true`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system cluster-switch show -is-monitoring-enabled-operational true*
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- ---------------
cs1                         cluster-network    10.233.205.92    NX3232C
     Serial Number: FOXXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

cs2                         cluster-network    10.233.205.93    NX3232C
     Serial Number: FOXXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

2 entries were displayed.
----
====


. Désactiver la restauration automatique sur les LIF du cluster.
+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*
----
====
. Sur le commutateur de cluster cs2, désactivez les ports connectés aux ports de cluster des nœuds.
+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs2(config)# *interface eth1/1/1-2,eth1/7-8*
cs2(config-if-range)# *shutdown*
----
====
. Vérifiez que les ports du cluster ont migré vers les ports hébergés sur le commutateur de cluster cs1. Cela peut prendre quelques secondes.
+
`network interface show -role cluster`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical           Status     Network            Current       Current Is
Vserver     Interface         Admin/Oper Address/Mask       Node          Port    Home
----------- ----------------- ---------- ------------------ ------------- ------- ----
Cluster
            cluster1-01_clus1 up/up      169.254.3.4/23     cluster1-01   e0a     true
            cluster1-01_clus2 up/up      169.254.3.5/23     cluster1-01   e0a     false
            cluster1-02_clus1 up/up      169.254.3.8/23     cluster1-02   e0a     true
            cluster1-02_clus2 up/up      169.254.3.9/23     cluster1-02   e0a     false
            cluster1-03_clus1 up/up      169.254.1.3/23     cluster1-03   e0a     true
            cluster1-03_clus2 up/up      169.254.1.1/23     cluster1-03   e0a     false
            cluster1-04_clus1 up/up      169.254.1.6/23     cluster1-04   e0a     true
            cluster1-04_clus2 up/up      169.254.1.7/23     cluster1-04   e0a     false
8 entries were displayed.
cluster1::*>
----
====
. Vérifiez que le cluster est sain :
+
`cluster show`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  -------
cluster1-01          true    true          false
cluster1-02          true    true          false
cluster1-03          true    true          true
cluster1-04          true    true          false
4 entries were displayed.
cluster1::*>
----
====
. Si vous ne l'avez pas déjà fait, enregistrez une copie de la configuration actuelle du commutateur en copiant le résultat de la commande suivante dans un fichier texte :
+
`show running-config`

. Enregistrez tout ajout personnalisé entre les éléments actuels `running-config` et le fichier RCF utilisé.
. Enregistrez les détails de configuration de base dans le `write_erase.cfg` fichier sur la mémoire flash de démarrage.
+

NOTE: Lors de la mise à niveau ou de l'application d'un nouveau RCF, vous devez effacer les paramètres du commutateur et effectuer la configuration de base. Vous devez être connecté au port de console série du commutateur pour configurer à nouveau le commutateur.

+
`cs2# show run | section "switchname" > bootflash:write_erase.cfg`

+
`cs2# show run | section "hostname" >> bootflash:write_erase.cfg`

+
`cs2# show run | i "username admin password" >> bootflash:write_erase.cfg`

+
`cs2# show run | section "vrf context management" >> bootflash:write_erase.cfg`

+
`cs2# show run | section "interface mgmt0" >> bootflash:write_erase.cfg`

. Pour RCF version 1.12 et ultérieures, exécutez les commandes suivantes :
+
`cs2# echo "hardware access-list tcam region racl-lite 512" >> bootflash:write_erase.cfg`

+
`cs2# echo "hardware access-list tcam region qos 256" >> bootflash:write_erase.cfg`

+
Consultez l'article de la base de connaissanceslink:https://kb.netapp.com/on-prem/Switches/Cisco-KBs/How_to_clear_configuration_on_a_Cisco_interconnect_switch_while_retaining_remote_connectivity["Comment effacer la configuration d'un commutateur d'interconnexion Cisco tout en conservant la connectivité à distance"^] pour plus de détails.

. Vérifiez que le `write_erase.cfg` Le fichier est rempli comme prévu :
+
`show file bootflash:write_erase.cfg`

. Émettre le `write erase` commande pour effacer la configuration enregistrée actuelle :
+
`cs2# *write erase*`

+
`Warning: This command will erase the startup-configuration.`

+
`Do you wish to proceed anyway? (y/n)  [n] *y*`

. Copiez la configuration de base précédemment enregistrée dans la configuration de démarrage.
+
`cs2# *copy bootflash:write_erase.cfg startup-config*`

. Redémarrez le commutateur :
+
`cs2# *reload*`

+
`This command will reboot the system. (y/n)?  [n] *y*`

. Copiez le RCF sur le bootflash du commutateur cs2 à l'aide de l'un des protocoles de transfert suivants : FTP, TFTP, SFTP ou SCP. Pour plus d'informations sur les commandes Cisco , consultez le guide approprié.link:https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Guide de référence des commandes NX-OS Cisco Nexus série 3000"^] guides.
+
.Afficher un exemple
[%collapsible]
====
Cet exemple montre comment TFTP est utilisé pour copier un RCF dans la mémoire flash de démarrage du commutateur cs2 :

[listing, subs="+quotes"]
----
cs2# *copy tftp: bootflash: vrf management*
Enter source filename: *Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt*
Enter hostname for the tftp server: *172.22.201.50*
Trying to connect to tftp server......Connection to Server Established.
TFTP get operation was successful
Copy complete, now saving to disk (please wait)...
----
====
. Appliquez le RCF précédemment téléchargé à la mémoire flash de démarrage.
+
Pour plus d'informations sur les commandes Cisco , consultez le guide approprié.link:https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Guide de référence des commandes NX-OS Cisco Nexus série 3000"^] guides.

+
.Afficher un exemple
[%collapsible]
====
Cet exemple montre le fichier RCF `Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt` en cours d'installation sur le commutateur cs2 :

[listing, subs="+quotes"]
----
cs2# *copy Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt running-config echo-commands*
----
====
. Examinez la sortie de la bannière à partir de `show banner motd` commande.  Vous devez lire et suivre les instructions figurant dans la section *Remarques importantes* pour assurer la configuration et le fonctionnement corrects du commutateur.
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cs2# show banner motd

******************************************************************************
* NetApp Reference Configuration File (RCF)
*
* Switch   : Cisco Nexus 3232C
* Filename : Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt
* Date     : Oct-20-2020
* Version  : v1.6
*
* Port Usage : Breakout configuration
* Ports  1- 3: Breakout mode (4x10GbE) Intra-Cluster Ports, int e1/1/1-4,
* e1/2/1-4, e1/3/1-4
* Ports  4- 6: Breakout mode (4x25GbE) Intra-Cluster/HA Ports, int e1/4/1-4,
* e1/5/1-4, e1/6/1-4
* Ports  7-30: 40/100GbE Intra-Cluster/HA Ports, int e1/7-30
* Ports 31-32: Intra-Cluster ISL Ports, int e1/31-32
* Ports 33-34: 10GbE Intra-Cluster 10GbE Ports, int e1/33-34
*
* IMPORTANT NOTES
* - Load Nexus_3232C_RCF_v1.6-Cluster-HA.txt for non breakout config
*
* - This RCF utilizes QoS and requires TCAM re-configuration, requiring RCF
*   to be loaded twice with the Cluster Switch rebooted in between.
*
* - Perform the following 4 steps to ensure proper RCF installation:
*
*   (1) Apply RCF first time, expect following messages:
*       - Please save config and reload the system...
*       - Edge port type (portfast) should only be enabled on ports...
*       - TCAM region is not configured for feature QoS class IPv4 ingress...
*
*   (2) Save running-configuration and reboot Cluster Switch
*
*   (3) After reboot, apply same RCF second time and expect following messages:
*       - % Invalid command at '^' marker
*       - Syntax error while parsing...
*
*   (4) Save running-configuration again
******************************************************************************
----
====
+

NOTE: Lors de la première application du RCF, le message *ERREUR : Échec de l’écriture des commandes VSH* est normal et peut être ignoré.

. Vérifiez que le fichier RCF est bien la version la plus récente correcte :
+
`show running-config`

+
Lorsque vous vérifiez le résultat pour vous assurer que vous avez le RCF correct, vérifiez que les informations suivantes sont correctes :

+
** La bannière RCF
** Paramètres du nœud et du port
** Personnalisations
+
Le résultat varie en fonction de la configuration de votre site.  Vérifiez les paramètres du port et consultez les notes de version pour connaître les modifications spécifiques à la version de RCF que vous avez installée.



. Réappliquez les personnalisations précédentes à la configuration du commutateur.  Se référer àlink:cabling-considerations-3232c.html["Examiner les considérations relatives au câblage et à la configuration"] pour plus de détails sur les modifications supplémentaires nécessaires.
. Après avoir vérifié que les versions RCF et les paramètres du commutateur sont corrects, copiez le fichier running-config dans le fichier startup-config.
+
Pour plus d'informations sur les commandes Cisco , consultez le guide approprié dans le https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Guide de référence des commandes NX-OS Cisco Nexus série 3000"^] guides.

+
[listing]
----
cs2# copy running-config startup-config [########################################] 100% Copy complete
----
. Redémarrez le commutateur cs2.  Vous pouvez ignorer les événements « ports de cluster hors service » signalés sur les nœuds pendant le redémarrage du commutateur.
+
[listing, subs="+quotes"]
----
cs2# *reload*
This command will reboot the system. (y/n)?  [n] *y*
----
. Appliquez le même RCF et enregistrez la configuration en cours une seconde fois.
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cs2# copy Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt running-config echo-commands
cs2# copy running-config startup-config [########################################] 100% Copy complete
----
====
. Vérifiez l'état des ports du cluster.
+
.. Vérifiez que les ports e0d sont opérationnels et fonctionnels sur tous les nœuds du cluster :
+
`network port show -role cluster`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -role cluster*

Node: cluster1-01
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-02
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-03
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false

Node: cluster1-04
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false
8 entries were displayed.
----
====
.. Vérifiez l'état du commutateur à partir du cluster (cela peut ne pas afficher le commutateur cs2, car les LIF ne sont pas hébergées sur e0d).
+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------- --------
cluster1-01/cdp
            e0a    cs1                       Ethernet1/7       N3K-C3232C
            e0d    cs2                       Ethernet1/7       N3K-C3232C
cluster01-2/cdp
            e0a    cs1                       Ethernet1/8       N3K-C3232C
            e0d    cs2                       Ethernet1/8       N3K-C3232C
cluster01-3/cdp
            e0a    cs1                       Ethernet1/1/1     N3K-C3232C
            e0b    cs2                       Ethernet1/1/1     N3K-C3232C
cluster1-04/cdp
            e0a    cs1                       Ethernet1/1/2     N3K-C3232C
            e0b    cs2                       Ethernet1/1/2     N3K-C3232C

cluster1::*> system cluster-switch show -is-monitoring-enabled-operational true
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- -----
cs1                         cluster-network    10.233.205.90    N3K-C3232C
     Serial Number: FOXXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

cs2                         cluster-network    10.233.205.91    N3K-C3232C
     Serial Number: FOXXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

2 entries were displayed.
----
====
+
[NOTE]
====
Vous pourriez observer le résultat suivant sur la console du commutateur cs1, en fonction de la version RCF précédemment chargée sur le commutateur.

....
2020 Nov 17 16:07:18 cs1 %$ VDC-1 %$ %STP-2-UNBLOCK_CONSIST_PORT: Unblocking port port-channel1 on VLAN0092. Port consistency restored.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_PEER: Blocking port-channel1 on VLAN0001. Inconsistent peer vlan.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_LOCAL: Blocking port-channel1 on VLAN0092. Inconsistent local vlan.
....
====


+

NOTE: Il peut falloir jusqu'à 5 minutes pour que les nœuds du cluster soient signalés comme étant en bonne santé.

. Sur le commutateur de cluster cs1, désactivez les ports connectés aux ports de cluster des nœuds.
+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant utilise la sortie d'exemple d'interface de l'étape 1 :

[listing, subs="+quotes"]
----
cs1(config)# *interface eth1/1/1-2,eth1/7-8*
cs1(config-if-range)# *shutdown*
----
====
. Vérifiez que les LIF du cluster ont migré vers les ports hébergés sur le commutateur cs2. Cela peut prendre quelques secondes.
+
`network interface show -role cluster`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical            Status     Network            Current             Current Is
Vserver     Interface          Admin/Oper Address/Mask       Node                Port    Home
----------- ------------------ ---------- ------------------ ------------------- ------- ----
Cluster
            cluster1-01_clus1  up/up      169.254.3.4/23     cluster1-01         e0d     false
            cluster1-01_clus2  up/up      169.254.3.5/23     cluster1-01         e0d     true
            cluster1-02_clus1  up/up      169.254.3.8/23     cluster1-02         e0d     false
            cluster1-02_clus2  up/up      169.254.3.9/23     cluster1-02         e0d     true
            cluster1-03_clus1  up/up      169.254.1.3/23     cluster1-03         e0b     false
            cluster1-03_clus2  up/up      169.254.1.1/23     cluster1-03         e0b     true
            cluster1-04_clus1  up/up      169.254.1.6/23     cluster1-04         e0b     false
            cluster1-04_clus2  up/up      169.254.1.7/23     cluster1-04         e0b     true
8 entries were displayed.
cluster1::*>
----
====
. Vérifiez que le cluster est sain :
+
`cluster show`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health   Eligibility   Epsilon
-------------------- -------- ------------- -------
cluster1-01          true     true          false
cluster1-02          true     true          false
cluster1-03          true     true          true
cluster1-04          true     true          false
4 entries were displayed.
cluster1::*>
----
====
. Répétez les étapes 7 à 23 sur le commutateur cs1.
. Activer la restauration automatique sur les LIF du cluster.
+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert true*
----
. Vérifiez que les ports du commutateur connectés aux ports du cluster sont opérationnels.
+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show interface brief | grep up*
.
.
Eth1/1/1      1       eth  access up      none                    10G(D) --
Eth1/1/2      1       eth  access up      none                    10G(D) --
Eth1/7        1       eth  trunk  up      none                   100G(D) --
Eth1/8        1       eth  trunk  up      none                   100G(D) --
.
.
----
====
. Vérifiez que l'ISL entre cs1 et cs2 est fonctionnel :
+
`show port-channel summary`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/31(P)   Eth1/32(P)
cs1#
----
====
. Vérifiez que les LIF du cluster sont revenues à leur port d'origine :
+
`network interface show -role cluster`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical            Status     Network            Current             Current Is
Vserver     Interface          Admin/Oper Address/Mask       Node                Port    Home
----------- ------------------ ---------- ------------------ ------------------- ------- ----
Cluster
            cluster1-01_clus1  up/up      169.254.3.4/23     cluster1-01         e0d     true
            cluster1-01_clus2  up/up      169.254.3.5/23     cluster1-01         e0d     true
            cluster1-02_clus1  up/up      169.254.3.8/23     cluster1-02         e0d     true
            cluster1-02_clus2  up/up      169.254.3.9/23     cluster1-02         e0d     true
            cluster1-03_clus1  up/up      169.254.1.3/23     cluster1-03         e0b     true
            cluster1-03_clus2  up/up      169.254.1.1/23     cluster1-03         e0b     true
            cluster1-04_clus1  up/up      169.254.1.6/23     cluster1-04         e0b     true
            cluster1-04_clus2  up/up      169.254.1.7/23     cluster1-04         e0b     true
8 entries were displayed.
cluster1::*>
----
====
+
Si des LIFS de cluster ne sont pas revenus à leurs ports d'origine, rétablissez-les manuellement :
`network interface revert -vserver _vserver_name_ -lif _lif_name_`

. Vérifiez que le cluster est sain :
+
`cluster show`

+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------- -------
cluster1-01          true    true          false
cluster1-02          true    true          false
cluster1-03          true    true          true
cluster1-04          true    true          false
4 entries were displayed.
cluster1::*>
----
====
. Vérifiez la connectivité des interfaces du cluster distant :


[role="tabbed-block"]
====
.ONTAP 9.9.1 et versions ultérieures
--
Vous pouvez utiliser le `network interface check cluster-connectivity` commande permettant de lancer une vérification d'accessibilité pour la connectivité du cluster, puis d'afficher les détails :

`network interface check cluster-connectivity start`et `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*REMARQUE :* Attendez quelques secondes avant d’exécuter le programme. `show` commande pour afficher les détails.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source              Destination         Packet
Node   Date                       LIF                 LIF                 Loss
------ -------------------------- ------------------- ------------------- -----------
cluster1-01
       3/5/2022 19:21:18 -06:00   cluster1-01_clus2   cluster1-02_clus1   none
       3/5/2022 19:21:20 -06:00   cluster1-01_clus2   cluster1-02_clus2   none
.
.
cluster1-02
       3/5/2022 19:21:18 -06:00   cluster1-02_clus2   cluster1-01_clus1   none
       3/5/2022 19:21:20 -06:00   cluster1-02_clus2   cluster1-01_clus2   none
.
.
cluster1-03
.
.
.
.
cluster1-04
.
.
.
.
----
--
.Toutes les versions ONTAP
--
Pour toutes les versions ONTAP , vous pouvez également utiliser `cluster ping-cluster -node <name>` commande pour vérifier la connectivité :

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is cluster1-03
Getting addresses from network interface table...
Cluster cluster1-03_clus1 169.254.1.3 cluster1-03 e0a
Cluster cluster1-03_clus2 169.254.1.1 cluster1-03 e0b
Cluster cluster1-04_clus1 169.254.1.6 cluster1-04 e0a
Cluster cluster1-04_clus2 169.254.1.7 cluster1-04 e0b
Cluster cluster1-01_clus1 169.254.3.4 cluster1-01 e0a
Cluster cluster1-01_clus2 169.254.3.5 cluster1-01 e0d
Cluster cluster1-02_clus1 169.254.3.8 cluster1-02 e0a
Cluster cluster1-02_clus2 169.254.3.9 cluster1-02 e0d
Local = 169.254.1.3 169.254.1.1
Remote = 169.254.1.6 169.254.1.7 169.254.3.4 169.254.3.5 169.254.3.8 169.254.3.9
Cluster Vserver Id = 4294967293
Ping status:
............
Basic connectivity succeeds on 12 path(s)
Basic connectivity fails on 0 path(s)
................................................
Detected 9000 byte MTU on 12 path(s):
    Local 169.254.1.3 to Remote 169.254.1.6
    Local 169.254.1.3 to Remote 169.254.1.7
    Local 169.254.1.3 to Remote 169.254.3.4
    Local 169.254.1.3 to Remote 169.254.3.5
    Local 169.254.1.3 to Remote 169.254.3.8
    Local 169.254.1.3 to Remote 169.254.3.9
    Local 169.254.1.1 to Remote 169.254.1.6
    Local 169.254.1.1 to Remote 169.254.1.7
    Local 169.254.1.1 to Remote 169.254.3.4
    Local 169.254.1.1 to Remote 169.254.3.5
    Local 169.254.1.1 to Remote 169.254.3.8
    Local 169.254.1.1 to Remote 169.254.3.9
Larger than PMTU communication succeeds on 12 path(s)
RPC status:
6 paths up, 0 paths down (tcp check)
6 paths up, 0 paths down (udp check)
----
--
====
.Quelle est la prochaine étape ?
link:configure-ssh-keys.html["Vérifier la configuration SSH"].
