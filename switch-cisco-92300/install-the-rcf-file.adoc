---
permalink: switch-cisco-92300/install-the-rcf-file.html 
sidebar: sidebar 
keywords: install, rcf 
summary: Vous pouvez installer le RCF après avoir configuré le commutateur Nexus 92300YC pour la première fois. 
---
= Installez le fichier de configuration de référence (RCF)
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Vous pouvez installer le RCF après avoir configuré le commutateur Nexus 92300YC pour la première fois. Vous pouvez également utiliser cette procédure pour mettre à niveau votre version RCF.

Consultez l'article de la base de connaissanceslink:https://kb.netapp.com/on-prem/Switches/Cisco-KBs/How_to_clear_configuration_on_a_Cisco_interconnect_switch_while_retaining_remote_connectivity["Comment effacer la configuration d'un commutateur d'interconnexion Cisco tout en conservant la connectivité à distance"^] pour plus d'informations lors de l'installation ou de la mise à niveau de votre RCF.

.À propos de cette tâche
Les exemples de cette procédure utilisent la nomenclature suivante pour les commutateurs et les nœuds :

* Les noms des deux commutateurs Cisco sont : `cs1` et `cs2` .
* Les noms des nœuds sont `node1` et `node2` .
* Les noms LIF du cluster sont `node1_clus1` , `node1_clus2` , `node2_clus1` , et `node2_clus2` .
* Le `cluster1::*>` L'invite indique le nom du cluster.


[NOTE]
====
* La procédure nécessite l'utilisation des commandes ONTAP et https://www.cisco.com/c/en/us/support/switches/nexus-9000-series-switches/series.html#InstallandUpgrade["Commutateurs Cisco Nexus série 9000"^] Les commandes ONTAP sont utilisées sauf indication contraire.
* Avant d'effectuer cette procédure, assurez-vous de disposer d'une sauvegarde récente de la configuration du commutateur.
* Aucune liaison inter-commutateurs opérationnelle (ISL) n'est nécessaire pendant cette procédure. Ceci est intentionnel car les changements de version RCF peuvent affecter temporairement la connectivité ISL. Pour garantir le fonctionnement non perturbateur du cluster, la procédure suivante migre toutes les LIF du cluster vers le commutateur partenaire opérationnel tout en exécutant les étapes sur le commutateur cible.


====
.Étapes
. Afficher les ports du cluster sur chaque nœud qui sont connectés aux commutateurs du cluster :
`network device-discovery show`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network device-discovery show*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ------------
node1/cdp
            e0a    cs1                       Ethernet1/1/1     N9K-C92300YC
            e0b    cs2                       Ethernet1/1/1     N9K-C92300YC
node2/cdp
            e0a    cs1                       Ethernet1/1/2     N9K-C92300YC
            e0b    cs2                       Ethernet1/1/2     N9K-C92300YC
cluster1::*>
----
====
. Vérifiez l'état administratif et opérationnel de chaque port du cluster.
+
.. Vérifiez que tous les ports du cluster sont opérationnels et en bon état :
`network port show -ipspace Cluster`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0c       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0c       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false
cluster1::*>
----
====
.. Vérifiez que toutes les interfaces du cluster (LIF) sont connectées au port d'accueil :
`network interface show -vserver Cluster`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical            Status     Network           Current      Current Is
Vserver     Interface          Admin/Oper Address/Mask      Node         Port    Home
----------- ------------------ ---------- ----------------- ------------ ------- ----
Cluster
            node1_clus1        up/up      169.254.3.4/23    node1        e0c     true
            node1_clus2        up/up      169.254.3.5/23    node1        e0d     true
            node2_clus1        up/up      169.254.3.8/23    node2        e0c     true
            node2_clus2        up/up      169.254.3.9/23    node2        e0d     true
cluster1::*>
----
====
.. Vérifiez que le cluster affiche les informations pour les deux commutateurs du cluster :
`system cluster-switch show -is-monitoring-enabled-operational true`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *system cluster-switch show -is-monitoring-enabled-operational true*
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- ---------------
cs1                         cluster-network    10.233.205.92    N9K-C92300YC
     Serial Number: FOXXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

cs2                         cluster-network    10.233.205.93    N9K-C92300YC
     Serial Number: FOXXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

2 entries were displayed.
----
====


. Désactiver la restauration automatique sur les LIF du cluster.
+
[listing, subs="+quotes"]
----
cluster1::*> **network interface modify -vserver Cluster -lif * -auto-revert false**
----
. Sur le commutateur de cluster cs2, désactivez les ports connectés aux ports de cluster des nœuds.
+
[listing, subs="+quotes"]
----
cs2(config)# *interface e1/1-64*
cs2(config-if-range)# *shutdown*
----
. Vérifiez que les ports du cluster ont migré vers les ports hébergés sur le commutateur de cluster cs1.  Cela peut prendre quelques secondes.
`network interface show -vserver Cluster`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical           Status     Network            Current       Current Is
Vserver     Interface         Admin/Oper Address/Mask       Node          Port    Home
----------- ----------------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1       up/up      169.254.3.4/23     node1         e0c     true
            node1_clus2       up/up      169.254.3.5/23     node1         e0c     false
            node2_clus1       up/up      169.254.3.8/23     node2         e0c     true
            node2_clus2       up/up      169.254.3.9/23     node2         e0c     false
cluster1::*>
----
====
. Vérifiez que le cluster est sain :
`cluster show`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *cluster show*
Node           Health  Eligibility   Epsilon
-------------- ------- ------------  -------
node1          true    true          false
node2          true    true          false
cluster1::*>
----
====
. Si vous ne l'avez pas déjà fait, enregistrez une copie de la configuration actuelle du commutateur en copiant le résultat de la commande suivante dans un fichier texte :
+
`show running-config`

. Nettoyez la configuration du commutateur CS2 et effectuez une configuration de base.
+

CAUTION: Lors de la mise à jour ou de l'application d'un nouveau RCF, vous devez effacer les paramètres du commutateur et effectuer une configuration de base. Vous devez être connecté au port de console série du commutateur pour configurer à nouveau le commutateur.

+
.. Nettoyer la configuration :
+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
(cs2)# *write erase*

Warning: This command will erase the startup-configuration.

Do you wish to proceed anyway? (y/n)  [n]  *y*
----
====
.. Redémarrez le commutateur :
+
.Afficher un exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
(cs2)# *reload*

Are you sure you would like to reset the system? (y/n) *y*

----
====


. Copiez le RCF sur le bootflash du commutateur cs2 à l'aide de l'un des protocoles de transfert suivants : FTP, TFTP, SFTP ou SCP. Pour plus d'informations sur les commandes Cisco , consultez le guide approprié dans le https://www.cisco.com/c/en/us/support/switches/nexus-9000-series-switches/series.html#InstallandUpgrade["Commutateurs Cisco Nexus série 9000"^] guides.
+
Cet exemple montre comment TFTP est utilisé pour copier un RCF dans la mémoire flash de démarrage du commutateur cs2 :

+
[listing, subs="+quotes"]
----
cs2# *copy tftp: bootflash: vrf management*
Enter source filename: */code/Nexus_92300YC_RCF_v1.0.2.txt*
Enter hostname for the tftp server: *172.19.2.1*
Enter username: *user1*

Outbound-ReKey for 172.19.2.1:22
Inbound-ReKey for 172.19.2.1:22
user1@172.19.2.1's password:
tftp> *progress*
Progress meter enabled
tftp> *get /code/Nexus_92300YC_RCF_v1.0.2.txt* /bootflash/nxos.9.2.2.bin
/code/Nexus_92300YC_R  100% 9687   530.2KB/s   00:00
tftp> *exit*
Copy complete, now saving to disk (please wait)...
Copy complete.
----
. Appliquez le RCF précédemment téléchargé à la mémoire flash de démarrage.
+
Pour plus d'informations sur les commandes Cisco , consultez le guide approprié dans le https://www.cisco.com/c/en/us/support/switches/nexus-9000-series-switches/series.html#InstallandUpgrade["Commutateurs Cisco Nexus série 9000"^] guides.

+
Cet exemple montre le fichier RCF `Nexus_92300YC_RCF_v1.0.2.txt` en cours d'installation sur le commutateur cs2 :

+
[listing, subs="+quotes"]
----
cs2# *copy Nexus_92300YC_RCF_v1.0.2.txt running-config echo-commands*

Disabling ssh: as its enabled right now:
 generating ecdsa key(521 bits)......
generated ecdsa key

Enabling ssh: as it has been disabled
 this command enables edge port type (portfast) by default on all interfaces. You
 should now disable edge port type (portfast) explicitly on switched ports leading to hubs,
 switches and bridges as they may create temporary bridging loops.

Edge port type (portfast) should only be enabled on ports connected to a single
 host. Connecting hubs, concentrators, switches, bridges, etc...  to this
 interface when edge port type (portfast) is enabled, can cause temporary bridging loops.
 Use with CAUTION

Edge Port Type (Portfast) has been configured on Ethernet1/1 but will only
 have effect when the interface is in a non-trunking mode.

...

Copy complete, now saving to disk (please wait)...
Copy complete.
----
. Vérifiez sur le commutateur que le RCF a été fusionné avec succès :
+
`show running-config`

+
[listing, subs="+quotes"]
----
cs2# *show running-config*
!Command: show running-config
!Running configuration last done at: Wed Apr 10 06:32:27 2019
!Time: Wed Apr 10 06:36:00 2019

version 9.2(2) Bios:version 05.33
switchname cs2
vdc cs2 id 1
  limit-resource vlan minimum 16 maximum 4094
  limit-resource vrf minimum 2 maximum 4096
  limit-resource port-channel minimum 0 maximum 511
  limit-resource u4route-mem minimum 248 maximum 248
  limit-resource u6route-mem minimum 96 maximum 96
  limit-resource m4route-mem minimum 58 maximum 58
  limit-resource m6route-mem minimum 8 maximum 8

feature lacp

no password strength-check
username admin password 5 $5$HY9Kk3F9$YdCZ8iQJ1RtoiEFa0sKP5IO/LNG1k9C4lSJfi5kesl
6  role network-admin
ssh key ecdsa 521

banner motd #
********************************************************************************
*                                                                              *
*  Nexus 92300YC Reference Configuration File (RCF) v1.0.2 (10-19-2018)        *
*                                                                              *
*  Ports 1/1  - 1/48: 10GbE Intra-Cluster Node Ports                           *
*  Ports 1/49 - 1/64: 40/100GbE Intra-Cluster Node Ports                       *
*  Ports 1/65 - 1/66: 40/100GbE Intra-Cluster ISL Ports                        *
*                                                                              *
********************************************************************************
----



NOTE: Lors de la première application du RCF, le message *ERREUR : Échec de l’écriture des commandes VSH* est normal et peut être ignoré.

. [[étape 12]]Vérifiez que le fichier RCF est la version la plus récente correcte :
`show running-config`
+
Lorsque vous vérifiez le résultat pour vous assurer que vous avez le RCF correct, vérifiez que les informations suivantes sont correctes :

+
** La bannière RCF
** Paramètres du nœud et du port
** Personnalisations
+
Le résultat varie en fonction de la configuration de votre site.  Vérifiez les paramètres du port et consultez les notes de version pour connaître les modifications spécifiques à la version de RCF que vous avez installée.



. Réappliquez les personnalisations précédentes à la configuration du commutateur.  Se référer àlink:cabling-considerations-92300.html["Examiner les considérations relatives au câblage et à la configuration"] pour plus de détails sur les modifications supplémentaires nécessaires.
. Après avoir vérifié que les versions RCF et les paramètres du commutateur sont corrects, copiez le fichier running-config dans le fichier startup-config.
+
Pour plus d'informations sur les commandes Cisco , consultez le guide approprié dans le https://www.cisco.com/c/en/us/support/switches/nexus-9000-series-switches/series.html#InstallandUpgrade["Commutateurs Cisco Nexus série 9000"^] guides.

+
[listing, subs="+quotes"]
----
cs2# *copy running-config startup-config*
[########################################] 100% Copy complete
----
. Redémarrez le commutateur cs2.  Vous pouvez ignorer les événements « ports de cluster hors service » signalés sur les nœuds pendant le redémarrage du commutateur.
+
[listing, subs="+quotes"]
----
cs2# *reload*
This command will reboot the system. (y/n)?  [n] *y*
----
. Vérifiez l'état des ports du cluster.
+
.. Vérifiez que les ports e0d sont opérationnels et fonctionnels sur tous les nœuds du cluster :
`network port show -ipspace Cluster`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false
----
====
.. Vérifiez l'état du commutateur à partir du cluster (cela peut ne pas afficher le commutateur cs2, car les LIF ne sont pas hébergées sur e0d).
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------- ------------
node1/cdp
            e0a    cs1                       Ethernet1/1       N9K-C92300YC
            e0b    cs2                       Ethernet1/1       N9K-C92300YC
node2/cdp
            e0a    cs1                       Ethernet1/2       N9K-C92300YC
            e0b    cs2                       Ethernet1/2       N9K-C92300YC

cluster1::*> *system cluster-switch show -is-monitoring-enabled-operational true*
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- ------------
cs1                         cluster-network    10.233.205.90    N9K-C92300YC
     Serial Number: FOXXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

cs2                         cluster-network    10.233.205.91    N9K-C92300YC
     Serial Number: FOXXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

2 entries were displayed.
----
====


+
[NOTE]
====
Vous pourriez observer le résultat suivant sur la console du commutateur cs1, en fonction de la version RCF précédemment chargée sur le commutateur.

....
2020 Nov 17 16:07:18 cs1 %$ VDC-1 %$ %STP-2-UNBLOCK_CONSIST_PORT: Unblocking port port-channel1 on VLAN0092. Port consistency restored.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_PEER: Blocking port-channel1 on VLAN0001. Inconsistent peer vlan.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_LOCAL: Blocking port-channel1 on VLAN0092. Inconsistent local vlan.
....
====
. Sur le commutateur de cluster cs1, désactivez les ports connectés aux ports de cluster des nœuds.
+
L'exemple suivant utilise la sortie d'exemple d'interface de l'étape 1 :

+
[listing, subs="+quotes"]
----
cs1(config)# *interface e1/1-64*
cs1(config-if-range)# *shutdown*
----
. Vérifiez que les LIF du cluster ont migré vers les ports hébergés sur le commutateur cs2.  Cela peut prendre quelques secondes. `network interface show -vserver Cluster`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical          Status     Network            Current           Current Is
Vserver     Interface        Admin/Oper Address/Mask       Node              Port    Home
----------- ---------------- ---------- ------------------ ----------------- ------- ----
Cluster
            node1_clus1      up/up      169.254.3.4/23     node1             e0d     false
            node1_clus2      up/up      169.254.3.5/23     node1             e0d     true
            node2_clus1      up/up      169.254.3.8/23     node2             e0d     false
            node2_clus2      up/up      169.254.3.9/23     node2             e0d     true
cluster1::*>
----
====
. Vérifiez que le cluster est sain :
`cluster show`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *cluster show*
Node           Health   Eligibility   Epsilon
-------------- -------- ------------- -------
node1          true     true          false
node2          true     true          false
cluster1::*>
----
====
. Répétez les étapes 7 à 14 sur le commutateur cs1.
. Activer la restauration automatique sur les LIF du cluster.
+
[listing, subs="+quotes"]
----
cluster1::*> **network interface modify -vserver Cluster -lif * -auto-revert True**
----
. Redémarrez le commutateur cs1.  Vous faites cela pour que les LIF du cluster reviennent à leurs ports d'origine.  Vous pouvez ignorer les événements « ports de cluster hors service » signalés sur les nœuds pendant le redémarrage du commutateur.
+
[listing, subs="+quotes"]
----
cs1# *reload*
This command will reboot the system. (y/n)?  [n] *y*
----
. Vérifiez que les ports du commutateur connectés aux ports du cluster sont opérationnels.
+
[listing, subs="+quotes"]
----
cs1# *show interface brief | grep up*
.
.
Ethernet1/1      1       eth  access up      none                    10G(D) --
Ethernet1/2      1       eth  access up      none                    10G(D) --
Ethernet1/3      1       eth  trunk  up      none                   100G(D) --
Ethernet1/4      1       eth  trunk  up      none                   100G(D) --
.
.
----
. Vérifiez que l'ISL entre cs1 et cs2 est fonctionnel :
`show port-channel summary`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cs1# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/65(P)   Eth1/66(P)
cs1#
----
====
. Vérifiez que les LIF du cluster sont revenues à leur port d'origine :
`network interface show -vserver Cluster`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical       Status     Network            Current       Current Is
Vserver     Interface     Admin/Oper Address/Mask       Node          Port    Home
----------- ------------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1   up/up      169.254.3.4/23     node1         e0d     true
            node1_clus2   up/up      169.254.3.5/23     node1         e0d     true
            node2_clus1   up/up      169.254.3.8/23     node2         e0d     true
            node2_clus2   up/up      169.254.3.9/23     node2         e0d     true
cluster1::*>
----
====
. Vérifiez que le cluster est sain :
`cluster show`
+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster1::*> *cluster show*
Node           Health  Eligibility   Epsilon
-------------- ------- ------------- -------
node1          true    true          false
node2          true    true          false
----
====
. Vérifiez la connectivité des interfaces du cluster distant :


[role="tabbed-block"]
====
.ONTAP 9.9.1 et versions ultérieures
--
Vous pouvez utiliser le `network interface check cluster-connectivity` commande permettant de lancer une vérification d'accessibilité pour la connectivité du cluster, puis d'afficher les détails :

`network interface check cluster-connectivity start`et `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*REMARQUE :* Attendez quelques secondes avant d’exécuter le programme. `show` commande pour afficher les détails.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Toutes les versions ONTAP
--
Pour toutes les versions ONTAP , vous pouvez également utiliser `cluster ping-cluster -node <name>` commande pour vérifier la connectivité :

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node1
Getting addresses from network interface table...
Cluster node1_clus1 169.254.3.4 node1 e0a
Cluster node1_clus2 169.254.3.5 node1 e0b
Cluster node2_clus1 169.254.3.8 node2 e0a
Cluster node2_clus2 169.254.3.9 node2 e0b
Local = 169.254.1.3 169.254.1.1
Remote = 169.254.1.6 169.254.1.7 169.254.3.4 169.254.3.5 169.254.3.8 169.254.3.9
Cluster Vserver Id = 4294967293
Ping status:
............
Basic connectivity succeeds on 12 path(s)
Basic connectivity fails on 0 path(s)
................................................
Detected 9000 byte MTU on 12 path(s):
    Local 169.254.1.3 to Remote 169.254.1.6
    Local 169.254.1.3 to Remote 169.254.1.7
    Local 169.254.1.3 to Remote 169.254.3.4
    Local 169.254.1.3 to Remote 169.254.3.5
    Local 169.254.1.3 to Remote 169.254.3.8
    Local 169.254.1.3 to Remote 169.254.3.9
    Local 169.254.1.1 to Remote 169.254.1.6
    Local 169.254.1.1 to Remote 169.254.1.7
    Local 169.254.1.1 to Remote 169.254.3.4
    Local 169.254.1.1 to Remote 169.254.3.5
    Local 169.254.1.1 to Remote 169.254.3.8
    Local 169.254.1.1 to Remote 169.254.3.9
Larger than PMTU communication succeeds on 12 path(s)
RPC status:
6 paths up, 0 paths down (tcp check)
6 paths up, 0 paths down (udp check)
----
--
====
.Quelle est la prochaine étape ?
link:configure-ssh-keys.html["Vérifier la configuration SSH"].
