---
permalink: switch-cisco-92300/install-nxos-overview.html 
sidebar: sidebar 
keywords: install nx-os rcf cisco nx 92300yc cluster switch 
summary: 'Le logiciel Cisco NX-OS et les fichiers de configuration de référence \(RCFs\) doivent être installés sur les commutateurs de cluster Cisco Nexus 92300YC.' 
---
= Installez le logiciel NX-OS et RCF sur les commutateurs de cluster Cisco Nexus 92300YC
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Le logiciel Cisco NX-OS et les fichiers RCFs (Reference Configuration File) doivent être installés sur les commutateurs de cluster Cisco Nexus 92300YC.

.Avant de commencer
Les conditions suivantes doivent exister avant d'installer le logiciel NX-OS et les fichiers de configurations de référence (RCFC) sur le commutateur de cluster :

* Le cluster doit fonctionner parfaitement (il ne doit y avoir aucune erreur dans les journaux ou d'autres problèmes similaires).
* Vous devez avoir vérifié ou défini la configuration de démarrage souhaitée dans la FCR pour qu'elle reflète les images de démarrage souhaitées si vous installez uniquement NX-OS et que vous gardez la version actuelle de RCF.
* Si vous devez modifier la configuration de démarrage pour qu'elle reflète les images de démarrage actuelles, vous devez le faire avant de réappliquer la FCR de sorte que la version correcte soit instanciée lors des prochains redémarrages.
* Vous devez avoir consulté la table de compatibilité des commutateurs sur le https://mysupport.netapp.com/site/info/cisco-ethernet-switch["Commutateur Ethernet Cisco"^] Consultez cette page pour les versions ONTAP, NX-OS et RCF prises en charge.
* Il peut y avoir des dépendances de commande entre la syntaxe de la commande dans la FCR et celle trouvée dans les versions de NX-OS.
* Vous devez vous être référé aux guides de mise à niveau et de logiciels appropriés disponibles sur le site Web de Cisco pour obtenir une documentation complète sur les procédures de mise à niveau et de mise à niveau vers une version antérieure du commutateur Cisco sur le https://www.cisco.com/c/en/us/support/switches/nexus-9000-series-switches/series.html#InstallandUpgrade["Commutateurs Cisco Nexus 9000 Series"^] page.
* Vous devez avoir la FCR actuelle.


.Description de la tâche
Les exemples de cette procédure utilisent deux nœuds. Ces nœuds utilisent deux ports d'interconnexion de cluster 10GbE `e0a` et `e0b`.

Voir la https://hwu.netapp.com/SWITCH/INDEX["Hardware Universe"^] pour vérifier les ports de cluster appropriés sur vos plates-formes.


NOTE: Les sorties de la commande peuvent varier en fonction des différentes versions d'ONTAP.

Les exemples de cette procédure utilisent la nomenclature des commutateurs et des nœuds suivante :

* Les noms des deux commutateurs Cisco sont `cs1` et `cs2`.
* Les noms de nœud sont `node1` et `node2`.
* Les noms LIF de cluster sont `node1_clus1` et `node1_clus2` pour les nœuds 1 et `node2_clus1` et `node2_clus2` pour le noeud 2.
* Le `cluster1::*>` l'invite indique le nom du cluster.



NOTE: La procédure nécessite l'utilisation des commandes ONTAP et des commutateurs Cisco Nexus 9000 ; les commandes ONTAP sont utilisées sauf indication contraire.

.Étapes
. Définissez le niveau de privilège sur avancé, en entrant *y* lorsque vous êtes invité à continuer :
+
`set -privilege advanced`

+
L'invite avancée (`*>`) s'affiche.

. Si AutoSupport est activé sur ce cluster, supprimez la création automatique de dossiers en invoquant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
où _x_ représente la durée de la fenêtre de maintenance en heures.

+

NOTE: Le message AutoSupport informe le support technique de cette tâche de maintenance de sorte que la création automatique de dossier soit supprimée lors de la fenêtre de maintenance.

+
La commande suivante supprime la création automatique de dossiers pendant deux heures :

+
[listing]
----
cluster1:> **system node autosupport invoke -node * -type all -message MAINT=2h**
----
. Afficher le nombre d'interfaces d'interconnexion de cluster configurées sur chaque nœud pour chaque commutateur d'interconnexion de cluster : `network device-discovery show -protocol cdp`
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*

 Node/      Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       Eth1/2            N9K-C92300YC
            e0b    cs2                       Eth1/2            N9K-C92300YC
node1      /cdp
            e0a    cs1                       Eth1/1            N9K-C92300YC
            e0b    cs2                       Eth1/1            N9K-C92300YC

4 entries were displayed.
----
. Vérifier le statut administratif ou opérationnel de chaque interface de cluster.
+
.. Afficher les attributs des ports réseau :  `network port show –ipspace Cluster`
+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node2
                                                  Speed(Mbps) Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status
--------- ------------ ---------------- ---- ---- ----------- --------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy
e0b       Cluster      Cluster          up   9000  auto/10000 healthy

Node: node1
                                                  Speed(Mbps) Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status
--------- ------------ ---------------- ---- ---- ----------- --------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy
e0b       Cluster      Cluster          up   9000  auto/10000 healthy

4 entries were displayed.
----
.. Afficher les informations relatives aux LIFs : `network interface show -vserver Cluster`
+
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e0b     true

4 entries were displayed.
----


. Exécutez une commande ping des LIFs de cluster distantes :
+
`cluster ping-cluster -node node-name`

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node node2*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1     e0a
Cluster node1_clus2 169.254.49.125 node1     e0b
Cluster node2_clus1 169.254.47.194 node2     e0a
Cluster node2_clus2 169.254.19.183 node2     e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:

Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)

Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
. Vérifier que la commande auto-revert est activée sur toutes les LIFs du cluster :
+
`network interface show -vserver Cluster -fields auto-revert`

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster -fields auto-revert*

          Logical
Vserver   Interface     Auto-revert
--------- ------------- ------------
Cluster
          node1_clus1   true
          node1_clus2   true
          node2_clus1   true
          node2_clus2   true

4 entries were displayed.
----

