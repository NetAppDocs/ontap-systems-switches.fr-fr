---
permalink: switch-netapp-cn1610/migrate-fas22xx-systems.html 
sidebar: sidebar 
keywords: migrate, two-node switched cluster, fas22xx systems, single, network connection 
summary: 'Si vous possédez des systèmes FAS22xx dans un cluster existant sans commutateur à deux nœuds dans lequel chaque module de contrôleur dispose d"une connexion 10 GbE unique et dos à dos pour la connectivité des clusters, vous pouvez utiliser l"option de réseau sans commutateur et remplacer la connectivité directe interne par des connexions de commutateurs.' 
---
= Migrez vers un cluster commuté à deux nœuds sur les systèmes FAS22xx avec une seule connexion cluster-network
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Si vous possédez des systèmes FAS22xx dans un cluster existant sans commutateur à deux nœuds dans lequel chaque module de contrôleur dispose d'une connexion 10 GbE unique et dos à dos pour la connectivité des clusters, vous pouvez utiliser l'option de réseau sans commutateur et remplacer la connectivité directe interne par des connexions de commutateurs.



== Examen des conditions requises

.Avant de commencer
Assurez-vous de disposer des éléments suivants :

* Deux connexions de cluster pour la migration d'une configuration sans commutateur vers une configuration avec commutateur.
* Le cluster est en bon état et se compose de deux nœuds connectés avec une connectivité dos à dos.
* Les nœuds exécutent ONTAP 8.2 ou une version ultérieure.
* La fonctionnalité de cluster sans commutateur ne peut pas être utilisée avec plus de deux nœuds.
* Tous les ports de cluster sont dans le `up` état.


.Informations associées
https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/How_to_suppress_automatic_case_creation_during_scheduled_maintenance_windows["Article 1010449 de la base de connaissances NetApp : comment supprimer la création automatique de dossiers pendant les fenêtres de maintenance planifiées"^]



== Migrer les commutateurs

Cette procédure constitue une procédure sans interruption qui supprime la connectivité directe du cluster dans un environnement sans commutateur et remplace chaque connexion au commutateur par une connexion au nœud partenaire.



=== Étape 1 : préparer la migration

. Modifiez le niveau de privilège en avancé, en saisissant `y` lorsque vous êtes invité à continuer :
+
`set -privilege advanced`

+
L'invite avancée (`*>`) s'affiche.

. Vérifiez l'état du cluster des nœuds sur la console système de l'un ou l'autre nœuds :
+
`cluster show`

+
.Montrer l'exemple
[%collapsible]
====
L'exemple suivant affiche des informations sur la santé et l'éligibilité des nœuds du cluster :

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Vérifier l'état de la paire HA sur la console système de n'importe quel nœud : `storage failover show`
+
.Montrer l'exemple
[%collapsible]
====
L'exemple suivant montre l'état du nœud 1 et du nœud 2 :

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Si AutoSupport est activé sur ce cluster, supprimez la création automatique de dossiers en invoquant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
`x` est la durée de la fenêtre de maintenance en heures.

+

NOTE: Ce message informe le support technique de cette tâche de maintenance de sorte que la création automatique de dossier soit supprimée lors de la fenêtre de maintenance.

+
.Montrer l'exemple
[%collapsible]
====
La commande suivante supprime la création automatique de dossiers pendant deux heures :

[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=2h
----
====
. Vérifiez que l'état actuel du cluster sans commutateur est de `true`, puis désactivez le mode cluster sans commutateur :
+
`network options switchless-cluster modify -enabled false`

. Reprendre le nœud cible :
+
`storage failover takeover -ofnode _target_node_name_`

+
Elle n'a pas d'importance sur le nœud cible. Lorsqu'il est pris en charge, le nœud cible redémarre et affiche automatiquement le `Waiting for giveback...` messagerie.

+
Le nœud actif transmet désormais les données du nœud partenaire (cible) pris en charge.

. Attendre deux minutes après le basculement du nœud douteux pour confirmer que le basculement a été effectué correctement.
. Le nœud cible affichant le `Waiting for giveback...` message, arrêtez-le.
+
La méthode que vous utilisez pour arrêter le nœud dépend si vous utilisez la gestion à distance par l'intermédiaire du processeur de service du nœud.

+
|===
| Si le processeur de service est | Alors... 


 a| 
Est configuré
 a| 
Connectez-vous au nœud SP douteux, puis mettez le système hors tension : `system power off`



 a| 
N'est pas configuré
 a| 
À l'invite du nœud douteux, appuyez sur `Ctrl-C`, puis répondez `y` pour arrêter le nœud.

|===




=== Étape 2 : configurer les câbles et les ports

. Sur chaque module de contrôleur, déconnectez le câble qui connecte le port de cluster 10 GbE au cluster sans commutateur.
. Connectez le port de cluster 10 GbE au commutateur des deux modules de contrôleur.
. Vérifiez que les ports de cluster 10 GbE connectés sur le commutateur sont configurés pour faire partie du même VLAN.
+
Si vous prévoyez de connecter les ports de cluster de chaque module de contrôleur à des commutateurs différents, vous devez vérifier que les ports sur lesquels les ports de cluster sont connectés sur chaque commutateur sont configurés pour le même VLAN et que l'agrégation est correctement configurée sur les deux commutateurs.

. Renvoyer le stockage au nœud cible :
+
`storage failover giveback -ofnode node2`

. Surveiller la progression de l'opération de rétablissement :
+
`storage failover show-giveback`

. Une fois l'opération de rétablissement terminée, vérifiez que la paire HA est saine et que le basculement est possible :
+
`storage failover show`

+
.Montrer l'exemple
[%collapsible]
====
La sortie doit être similaire à ce qui suit :

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Vérifiez que les LIFs de port du cluster fonctionnent correctement :
+
`network interface show -role cluster`

+
.Montrer l'exemple
[%collapsible]
====
L'exemple suivant montre que les LIFs sont `up` Sur les noeuds 1 et node2 et que les résultats de la colonne "est à la maison" sont `true`:

[listing]
----

cluster::*> network interface show -role cluster
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
node1
            clus1        up/up    192.168.177.121/24  node1        e1a     true
node2
            clus1        up/up    192.168.177.123/24  node2        e1a     true

2 entries were displayed.
----
====
. Vérifiez l'état du cluster des nœuds sur la console système de l'un ou l'autre nœuds :
+
`cluster show`

+
.Montrer l'exemple
[%collapsible]
====
L'exemple suivant affiche des informations sur la santé et l'éligibilité des nœuds du cluster :

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Vérifiez la connectivité des interfaces de cluster distantes :


[role="tabbed-block"]
====
.ONTAP 9.9.1 et versions ultérieures
--
Vous pouvez utiliser le `network interface check cluster-connectivity` pour lancer un contrôle d'accessibilité pour la connectivité du cluster, puis afficher les détails :

`network interface check cluster-connectivity start` et `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*REMARQUE :* attendez un certain nombre de secondes avant d'exécuter `show` la commande pour afficher les détails.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Toutes les versions de ONTAP
--
Pour toutes les versions de ONTAP, vous pouvez également utiliser `cluster ping-cluster -node <name>` pour vérifier la connectivité :

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====


=== Étape 3 : réaliser la procédure

. Si vous avez supprimé la création automatique de cas, réactivez-la en appelant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`

+
.Montrer l'exemple
[%collapsible]
====
[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=END
----
====
. Rétablissez le niveau de privilège sur admin :
+
`set -privilege admin`


