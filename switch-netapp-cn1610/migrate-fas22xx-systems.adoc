---
permalink: switch-netapp-cn1610/migrate-fas22xx-systems.html 
sidebar: sidebar 
keywords: migrate, two-node switched cluster, fas22xx systems, single, network connection 
summary: 'Si vous disposez de systèmes FAS22xx dans un cluster existant à deux nœuds sans commutateur, dans lequel chaque module de contrôleur dispose d"une seule connexion 10 GbE directe pour la connectivité du cluster, vous pouvez utiliser l"option de réseau de cluster sans commutateur et remplacer la connectivité directe directe par des connexions de commutateur.' 
---
= Migration vers un cluster commuté à deux nœuds dans les systèmes FAS22xx avec une seule connexion réseau de cluster
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Si vous disposez de systèmes FAS22xx dans un cluster existant à deux nœuds sans commutateur, dans lequel chaque module de contrôleur dispose d'une seule connexion 10 GbE directe pour la connectivité du cluster, vous pouvez utiliser l'option de réseau de cluster sans commutateur et remplacer la connectivité directe directe par des connexions de commutateur.



== Exigences de révision

.Avant de commencer
Assurez-vous d'avoir les éléments suivants :

* Deux connexions de cluster pour la migration d'une configuration sans commutateur vers une configuration commutée.
* Le cluster est sain et se compose de deux nœuds connectés en tandem.
* Les nœuds exécutent ONTAP 8.2 ou une version ultérieure.
* La fonctionnalité de cluster sans commutateur ne peut pas être utilisée avec plus de deux nœuds.
* Tous les ports du cluster sont dans le `up` État.


.Informations connexes
https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/How_to_suppress_automatic_case_creation_during_scheduled_maintenance_windows["Article 1010449 de la base de connaissances NetApp : Comment désactiver la création automatique de tickets pendant les fenêtres de maintenance planifiées"^]



== Déplacer les commutateurs

Cette procédure non perturbatrice supprime la connectivité directe au cluster dans un environnement sans commutateur et remplace chaque connexion au commutateur par une connexion au nœud partenaire.



=== Étape 1 : Préparer la migration

. Modifiez le niveau de privilège en avancé, puis saisissez `y` lorsqu'on vous invite à continuer :
+
`set -privilege advanced`

+
L'invite avancée(`*>` ) apparaît.

. Vérifiez l'état du cluster des nœuds sur la console système de l'un ou l'autre nœud :
+
`cluster show`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant présente des informations sur l'état et l'éligibilité des nœuds du cluster :

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Vérifiez l'état de la paire HA sur la console système de l'un ou l'autre nœud : `storage failover show`
+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant illustre l'état des nœuds 1 et 2 :

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Si AutoSupport est activé sur ce cluster, supprimez la création automatique de cas en envoyant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
`x`Il s'agit de la durée de la fenêtre de maintenance en heures.

+

NOTE: Ce message informe le support technique de cette tâche de maintenance afin que la création automatique de tickets soit désactivée pendant la période de maintenance.

+
.Afficher un exemple
[%collapsible]
====
La commande suivante désactive la création automatique de cas pendant deux heures :

[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=2h
----
====
. Vérifiez que l'état actuel du cluster sans commutateur est `true` , puis désactivez le mode cluster sans commutateur :
+
`network options switchless-cluster modify -enabled false`

. Prendre le contrôle du nœud cible :
+
`storage failover takeover -ofnode _target_node_name_`

+
Peu importe quel nœud est le nœud cible.  Lorsqu'il est pris en charge, le nœud cible redémarre automatiquement et affiche le `Waiting for giveback...` message.

+
Le nœud actif fournit désormais des données au nœud partenaire (cible) qui a été pris en charge.

. Attendez deux minutes après la prise de contrôle du nœud défaillant pour confirmer que la prise de contrôle s'est déroulée avec succès.
. Avec le nœud cible affichant le `Waiting for giveback...` message, fermez-le.
+
La méthode que vous utilisez pour arrêter le nœud dépend de si vous utilisez la gestion à distance via le processeur de service du nœud (SP).

+
|===
| Si SP | Alors... 


 a| 
Est configuré
 a| 
Connectez-vous au nœud défaillant SP, puis mettez le système hors tension : `system power off`



 a| 
N'est pas configuré
 a| 
À l'invite du nœud défectueux, appuyez sur `Ctrl-C` , puis répondez `y` pour arrêter le nœud.

|===




=== Étape 2 : Configurer les câbles et les ports

. Sur chaque module de contrôleur, débranchez le câble qui relie le port de cluster 10 GbE au cluster sans commutateur.
. Connectez le port du cluster 10 GbE au commutateur sur les deux modules de contrôleur.
. Vérifiez que les ports du cluster 10 GbE connectés au commutateur sont configurés pour faire partie du même VLAN.
+
Si vous prévoyez de connecter les ports de cluster de chaque module de contrôleur à des commutateurs différents, vous devez vérifier que les ports auxquels les ports de cluster sont connectés sur chaque commutateur sont configurés pour le même VLAN et que le trunking est correctement configuré sur les deux commutateurs.

. Restituer l'espace de stockage au nœud cible :
+
`storage failover giveback -ofnode node2`

. Suivre l'avancement de l'opération de restitution :
+
`storage failover show-giveback`

. Une fois l'opération de restitution terminée, vérifiez que la paire HA est saine et que la prise de contrôle est possible :
+
`storage failover show`

+
.Afficher un exemple
[%collapsible]
====
Le résultat devrait être similaire à ce qui suit :

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Vérifiez que les interfaces logiques (LIF) des ports du cluster fonctionnent correctement :
+
`network interface show -role cluster`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant montre que les LIF sont `up` sur les nœuds 1 et 2 et que les résultats de la colonne « Est à la maison » sont `true` :

[listing]
----

cluster::*> network interface show -role cluster
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
node1
            clus1        up/up    192.168.177.121/24  node1        e1a     true
node2
            clus1        up/up    192.168.177.123/24  node2        e1a     true

2 entries were displayed.
----
====
. Vérifiez l'état du cluster des nœuds sur la console système de l'un ou l'autre nœud :
+
`cluster show`

+
.Afficher un exemple
[%collapsible]
====
L'exemple suivant présente des informations sur l'état et l'éligibilité des nœuds du cluster :

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Vérifiez la connectivité des interfaces du cluster distant :


[role="tabbed-block"]
====
.ONTAP 9.9.1 et versions ultérieures
--
Vous pouvez utiliser le `network interface check cluster-connectivity` commande permettant de lancer une vérification d'accessibilité pour la connectivité du cluster, puis d'afficher les détails :

`network interface check cluster-connectivity start`et `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*REMARQUE :* Attendez quelques secondes avant d’exécuter le programme. `show` commande pour afficher les détails.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Toutes les versions ONTAP
--
Pour toutes les versions ONTAP , vous pouvez également utiliser `cluster ping-cluster -node <name>` commande pour vérifier la connectivité :

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====


=== Étape 3 : Terminer la procédure

. Si vous avez désactivé la création automatique de dossiers, réactivez-la en envoyant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`

+
.Afficher un exemple
[%collapsible]
====
[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=END
----
====
. Rétablir le niveau de privilège à administrateur :
+
`set -privilege admin`


