---
permalink: switch-nvidia-sn2100/replace-sn2100-switch-cluster.html 
sidebar: sidebar 
keywords: replacing, replace, defective, nvidia, switch, cluster, network, nondisruptive, procedure, ndu, replace a nvidia msn2100 cluster switch - nvidia SN2100 
summary: 'Le remplacement d"un commutateur NVIDIA SN2100 défectueux dans un réseau en cluster est une procédure non perturbatrice (NDU).' 
---
= Remplacer un commutateur de cluster NVIDIA SN2100
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Suivez cette procédure pour remplacer un commutateur NVIDIA SN2100 défectueux dans un réseau en cluster. Il s’agit d’une procédure non perturbatrice (NDU).



== Exigences de révision

.Infrastructure de cluster et de réseau existante
Assurez-vous que :

* Le cluster existant est vérifié comme étant entièrement fonctionnel, avec au moins un commutateur de cluster entièrement connecté.
* Tous les ports du cluster sont opérationnels.
* Toutes les interfaces logiques du cluster (LIF) sont opérationnelles et connectées à leurs ports d'origine.
* L' ONTAP `cluster ping-cluster -node node1` Cette commande indique que la connectivité de base et les communications supérieures à PMTU sont réussies sur tous les chemins.


.Interrupteur de remplacement NVIDIA SN2100
Assurez-vous que :

* La connectivité du réseau de gestion sur le commutateur de remplacement est fonctionnelle.
* L'accès console au commutateur de remplacement est en place.
* Les connexions du nœud sont les ports swp1 à swp14.
* Tous les ports Inter-Switch Link (ISL) sont désactivés sur les ports swp15 et swp16.
* Le fichier de configuration de référence (RCF) souhaité et le commutateur d'image du système d'exploitation Cumulus sont chargés sur le commutateur.
* La personnalisation initiale du commutateur est terminée.


Assurez-vous également que toutes les personnalisations précédentes du site, telles que STP, SNMP et SSH, soient copiées sur le nouveau commutateur.


NOTE: Vous devez exécuter la commande de migration d'un LIF de cluster depuis le nœud où est hébergé le LIF de cluster.



== Activer la journalisation de la console

NetApp vous recommande vivement d'activer la journalisation de la console sur les périphériques que vous utilisez et de prendre les mesures suivantes lors du remplacement de votre commutateur :

* Laissez AutoSupport activé pendant la maintenance.
* Déclenchez une intervention de maintenance AutoSupport avant et après la maintenance afin de désactiver la création de tickets pendant toute la durée de celle-ci.  Consultez cet article de la base de connaissances https://kb.netapp.com/Support_Bulletins/Customer_Bulletins/SU92["SU92 : Comment désactiver la création automatique de tickets pendant les fenêtres de maintenance planifiées ?"^] pour plus de détails.
* Activez la journalisation des sessions pour toutes les sessions CLI.  Pour savoir comment activer la journalisation des sessions, consultez la section « Journalisation des sorties de session » de cet article de la base de connaissances. https://kb.netapp.com/on-prem/ontap/Ontap_OS/OS-KBs/How_to_configure_PuTTY_for_optimal_connectivity_to_ONTAP_systems["Comment configurer PuTTY pour une connectivité optimale aux systèmes ONTAP"^] .




== Remplacez l'interrupteur

.À propos des exemples
Les exemples de cette procédure utilisent la nomenclature suivante pour les commutateurs et les nœuds :

* Les noms des commutateurs NVIDIA SN2100 existants sont _sw1_ et _sw2_.
* Le nom du nouveau commutateur NVIDIA SN2100 est _nsw2_.
* Les noms des nœuds sont _node1_ et _node2_.
* Les ports du cluster sur chaque nœud sont nommés _e3a_ et _e3b_.
* Les noms LIF du cluster sont _node1_clus1_ et _node1_clus2_ pour le nœud 1, et _node2_clus1_ et _node2_clus2_ pour le nœud 2.
* L'invite pour les modifications apportées à tous les nœuds du cluster est `cluster1::*>`
* Les ports de dérivation prennent le format : swp[port]s[port de dérivation 0-3].  Par exemple, quatre ports de dérivation sur swp1 sont _swp1s0_, _swp1s1_, _swp1s2_ et _swp1s3_.


.À propos de la topologie du réseau en cluster
Cette procédure est basée sur la topologie de réseau de clusters suivante :

.Afficher un exemple de topologie
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false


cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true


cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3          -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4          -
----
+

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw2                e3a
swp4       100G   Trunk/L2    sw2                e3a
swp15      100G   BondMember  sw2                swp15
swp16      100G   BondMember  sw2                swp16


cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw1                e3b
swp4       100G   Trunk/L2    sw1                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
====


=== Étape 1 : Préparer le remplacement

. Si AutoSupport est activé sur ce cluster, supprimez la création automatique de cas en envoyant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
où _x_ représente la durée de la fenêtre de maintenance en heures.

. Passez au niveau de privilège avancé en saisissant *y* lorsque vous êtes invité à continuer :
+
`set -privilege advanced`

+
L'invite avancée (*>) apparaît.

. Installez le RCF et l'image appropriés sur le commutateur, nsw2, et effectuez toutes les préparations de site nécessaires.
+
Si nécessaire, vérifiez, téléchargez et installez les versions appropriées des logiciels RCF et Cumulus pour le nouveau commutateur.

+
.. Vous pouvez télécharger le logiciel Cumulus adapté à vos commutateurs de cluster depuis le site d'assistance NVIDIA.  Suivez les étapes indiquées sur la page de téléchargement pour télécharger Cumulus Linux correspondant à la version du logiciel ONTAP que vous installez.
.. Le RCF approprié est disponible auprès delink:https://mysupport.netapp.com/site/products/all/details/nvidia-cluster-storage-switch/downloads-tab["_Commutateurs de cluster et de stockage NVIDIA_"^] page.  Suivez les étapes indiquées sur la page de téléchargement pour télécharger le fichier RCF correspondant à la version du logiciel ONTAP que vous installez.






=== Étape 2 : Configurer les ports et le câblage

[role="tabbed-block"]
====
.Cumulus Linux 4.4.3
--
. Sur le nouveau commutateur nsw2, connectez-vous en tant qu'administrateur et fermez tous les ports qui seront connectés aux interfaces du cluster de nœuds (ports swp1 à swp14).
+
Les interfaces logiques (LIF) des nœuds du cluster auraient déjà dû basculer vers l'autre port du cluster pour chaque nœud.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net add interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Désactiver la restauration automatique sur les LIF du cluster :
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Vérifiez que la restauration automatique est désactivée pour tous les LIF du cluster :
+
`net interface show -vserver Cluster -fields auto-revert`

. Fermez les ports ISL swp15 et swp16 sur le commutateur SN2100 sw1.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net add interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
. Retirez tous les câbles du commutateur SN2100 sw1, puis connectez-les aux mêmes ports du commutateur SN2100 nsw2.
. Activez les ports ISL swp15 et swp16 entre les commutateurs sw1 et nsw2.
+
Les commandes suivantes activent les ports ISL swp15 et swp16 sur le commutateur sw1 :

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net del interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
+
L'exemple suivant montre que les ports ISL sont actifs sur le commutateur sw1 :

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
L'exemple suivant montre que les ports ISL sont opérationnels sur le commutateur nsw2 :

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Vérifiez ce port `e3b` est opérationnel sur tous les nœuds :
+
`network port show -ipspace Cluster`

+
Le résultat devrait être similaire à ce qui suit :

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Du point de vue des nœuds, les ports du cluster sur chaque nœud sont désormais connectés aux commutateurs du cluster de la manière suivante :
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Vérifiez que tous les ports du cluster de nœuds sont actifs :
+
`net show interface`

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Vérifiez que chaque nœud possède une connexion à chaque commutateur :
+
`net show lldp`

+
L'exemple suivant illustre les résultats attendus pour les deux commutateurs :

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Activer la restauration automatique sur les LIF du cluster :
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Sur le commutateur nsw2, activez les ports connectés aux ports réseau des nœuds.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net del interface swp1-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Afficher les informations relatives aux nœuds d'un cluster :
+
`cluster show`

+
Cet exemple montre que l'état de santé des nœuds node1 et node2 de ce cluster est correct :

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Vérifiez que tous les ports physiques du cluster sont opérationnels :
+
`network port show ipspace Cluster`

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false
----


--
.Cumulus Linux 5.x
--
. Sur le nouveau commutateur nsw2, connectez-vous en tant qu'administrateur et fermez tous les ports qui seront connectés aux interfaces du cluster de nœuds (ports swp1 à swp14).
+
Les interfaces logiques (LIF) des nœuds du cluster auraient déjà dû basculer vers l'autre port du cluster pour chaque nœud.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv set interface swp15-16 link state down*
cumulus@nsw2:~$ *nv config apply*
----
. Désactiver la restauration automatique sur les LIF du cluster :
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Vérifiez que la restauration automatique est désactivée pour tous les LIF du cluster :
+
`network interface show -vserver Cluster -fields auto-revert`

. Fermez les ports ISL swp15 et swp16 sur le commutateur SN2100 sw1.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv set interface swp15-16 link state down*
cumulus@sw1:~$ *nv config apply*
----
. Retirez tous les câbles du commutateur SN2100 sw1, puis connectez-les aux mêmes ports du commutateur SN2100 nsw2.
. Activez les ports ISL swp15 et swp16 entre les commutateurs sw1 et nsw2.
+
Les commandes suivantes activent les ports ISL swp15 et swp16 sur le commutateur sw1 :

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv set interface swp15-16 link state down*
cumulus@sw1:~$ *nv config apply*
----
+
L'exemple suivant montre que les ports ISL sont actifs sur le commutateur sw1 :

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
L'exemple suivant montre que les ports ISL sont opérationnels sur le commutateur nsw2 :

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Vérifiez ce port `e3b` est opérationnel sur tous les nœuds :
+
`network port show -ipspace Cluster`

+
Le résultat devrait être similaire à ce qui suit :

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Du point de vue des nœuds, les ports du cluster sur chaque nœud sont désormais connectés aux commutateurs du cluster de la manière suivante :
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Vérifiez que tous les ports du cluster de nœuds sont actifs :
+
`nv show interface`

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Vérifiez que chaque nœud possède une connexion à chaque commutateur :
+
`nv show interface lldp`

+
L'exemple suivant illustre les résultats attendus pour les deux commutateurs :

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Activer la restauration automatique sur les LIF du cluster :
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Sur le commutateur nsw2, activez les ports connectés aux ports réseau des nœuds.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv set interface swp1-14 link state up*
cumulus@nsw2:~$ *nv config apply*
----
. Afficher les informations relatives aux nœuds d'un cluster :
+
`cluster show`

+
Cet exemple montre que l'état de santé des nœuds node1 et node2 de ce cluster est correct :

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Vérifiez que tous les ports physiques du cluster sont opérationnels :
+
`network port show ipspace Cluster`

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false
----


--
====


=== Étape 3 : Vérifier la configuration

[role="tabbed-block"]
====
.Cumulus Linux 4.4.3
--
. Vérifiez que le réseau du cluster est sain.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----


--
.Cumulus Linux 5.x
--
. Vérifiez que le réseau du cluster est sain.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----


--
====
. [[étape 2]] Rétablir le niveau de privilège à administrateur :
+
`set -privilege admin`

. Si vous avez désactivé la création automatique de dossiers, réactivez-la en envoyant un message AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.Quelle est la prochaine étape ?
Après avoir remplacé vos interrupteurs, vous pouvez link:../switch-cshm/config-overview.html["configurer la surveillance de l'état du commutateur"].
