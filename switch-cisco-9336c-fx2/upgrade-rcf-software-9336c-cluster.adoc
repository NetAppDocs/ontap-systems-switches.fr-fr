---
permalink: switch-cisco-9336c-fx2/upgrade-rcf-software-9336c-cluster.html 
sidebar: sidebar 
keywords: install rcf, cisco switches 
summary: Vous pouvez installer la FCR après la première configuration du commutateur Nexus 9336C-FX2.vous pouvez également utiliser cette procédure pour mettre à niveau votre version FCR. 
---
= Mettez à niveau votre fichier de configuration de référence (RCF)
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Vous mettez à niveau votre version RCF si une version existante du fichier RCF est installée sur vos switchs opérationnels.

.Avant de commencer
Assurez-vous de disposer des éléments suivants :

* Sauvegarde actuelle de la configuration du commutateur.
* Cluster totalement opérationnel (aucune erreur dans les journaux ou problèmes similaires).
* La FCR actuelle.
* Si vous mettez à jour votre version RCF, vous avez besoin d'une configuration d'amorçage dans la mémoire RCF qui reflète les images d'amorçage souhaitées.
+
Si vous devez modifier la configuration de démarrage pour qu'elle reflète les images de démarrage actuelles, vous devez le faire avant de réappliquer la FCR de sorte que la version correcte soit instanciée lors des prochains redémarrages.




NOTE: Aucune liaison inter-commutateurs (ISL) opérationnelle n'est nécessaire au cours de cette procédure. Ceci est de par sa conception, car les modifications de version des fichiers RCF peuvent affecter temporairement la connectivité ISL. Pour assurer un fonctionnement sans interruption du cluster, la procédure suivante migre toutes les LIFs du cluster vers le commutateur partenaire opérationnel tout en effectuant les étapes sur le commutateur cible.


CAUTION: Avant d'installer une nouvelle version du logiciel de commutateur et des RCFs, vous devez effacer les paramètres du commutateur et effectuer la configuration de base. Vous devez être connecté au commutateur à l'aide de la console série ou avoir conservé les informations de configuration de base avant d'effacer les paramètres du commutateur.



== Étape 1 : préparation de la mise à niveau

. Afficher les ports de cluster sur chaque nœud connecté aux commutateurs du cluster :
+
`network device-discovery show`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  --------
cluster1-01/cdp
            e0a    cs1                       Ethernet1/7       N9K-C9336C
            e0d    cs2                       Ethernet1/7       N9K-C9336C
cluster1-02/cdp
            e0a    cs1                       Ethernet1/8       N9K-C9336C
            e0d    cs2                       Ethernet1/8       N9K-C9336C
cluster1-03/cdp
            e0a    cs1                       Ethernet1/1/1     N9K-C9336C
            e0b    cs2                       Ethernet1/1/1     N9K-C9336C
cluster1-04/cdp
            e0a    cs1                       Ethernet1/1/2     N9K-C9336C
            e0b    cs2                       Ethernet1/1/2     N9K-C9336C
cluster1::*>
----
====
. Vérifiez le statut administratif et opérationnel de chaque port du cluster.
+
.. Vérifiez que tous les ports du cluster sont *up* avec un état sain :
+
`network port show -role cluster`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -role cluster*

Node: cluster1-01
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false

Node: cluster1-02
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false
8 entries were displayed.

Node: cluster1-03

   Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-04
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false
cluster1::*>
----
====
.. Vérifier que toutes les interfaces de cluster (LIFs) sont sur le port de home port :
+
`network interface show -role cluster`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical            Status     Network           Current      Current Is
Vserver     Interface          Admin/Oper Address/Mask      Node         Port    Home
----------- ------------------ ---------- ----------------- ------------ ------- ----
Cluster
            cluster1-01_clus1  up/up     169.254.3.4/23     cluster1-01  e0a     true
            cluster1-01_clus2  up/up     169.254.3.5/23     cluster1-01  e0d     true
            cluster1-02_clus1  up/up     169.254.3.8/23     cluster1-02  e0a     true
            cluster1-02_clus2  up/up     169.254.3.9/23     cluster1-02  e0d     true
            cluster1-03_clus1  up/up     169.254.1.3/23     cluster1-03  e0a     true
            cluster1-03_clus2  up/up     169.254.1.1/23     cluster1-03  e0b     true
            cluster1-04_clus1  up/up     169.254.1.6/23     cluster1-04  e0a     true
            cluster1-04_clus2  up/up     169.254.1.7/23     cluster1-04  e0b     true
8 entries were displayed.
cluster1::*>
----
====
.. Vérifiez que le cluster affiche les informations relatives aux deux commutateurs de cluster :
+
`system cluster-switch show -is-monitoring-enabled-operational true`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system cluster-switch show -is-monitoring-enabled-operational true*
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- -----
cs1                         cluster-network    10.233.205.90    N9K-C9336C
     Serial Number: FOCXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(5)
    Version Source: CDP

cs2                         cluster-network    10.233.205.91    N9K-C9336C
     Serial Number: FOCXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(5)
    Version Source: CDP
cluster1::*>
----
====


. Désactivez la fonction de restauration automatique sur les LIF du cluster.
+
`cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*`





== Étape 2 : configurer les ports

. Sur le commutateur de cluster cs1, arrêtez les ports connectés aux ports de cluster des nœuds.
+
`cs1> *enable*`

+
`cs1# *configure*`

+
`cs1(config)# *interface eth1/1/1-2,eth1/7-8*`

+
`cs1(config-if-range)# *shutdown*`

+
`cs1(config-if-range)# *exit*`

+
`cs1# *exit*`

+

CAUTION: Assurez-vous d'arrêter *tous* ports de cluster connectés pour éviter tout problème de connexion réseau. Consultez l'article de la base de connaissances https://kb.netapp.com/on-prem/ontap/OHW/OHW-KBs/Node_out_of_quorum_when_migrating_cluster_lif_during_switch_OS_upgrade["Le nœud n'a pas le quorum lors de la migration de la LIF du cluster pendant la mise à niveau du système d'exploitation du commutateur"^] pour plus de détails.

. Vérifiez que les LIFs du cluster ont basculé vers les ports hébergés sur le commutateur de cluster cs1. Cette opération peut prendre quelques secondes.
+
`network interface show -role cluster`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical           Status     Network            Current       Current Is
Vserver     Interface         Admin/Oper Address/Mask       Node          Port    Home
----------- ----------------- ---------- ------------------ ------------- ------- ----
Cluster
            cluster1-01_clus1 up/up      169.254.3.4/23     cluster1-01   e0a     true
            cluster1-01_clus2 up/up      169.254.3.5/23     cluster1-01   e0a     false
            cluster1-02_clus1 up/up      169.254.3.8/23     cluster1-02   e0a     true
            cluster1-02_clus2 up/up      169.254.3.9/23     cluster1-02   e0a     false
            cluster1-03_clus1 up/up      169.254.1.3/23     cluster1-03   e0a     true
            cluster1-03_clus2 up/up      169.254.1.1/23     cluster1-03   e0a     false
            cluster1-04_clus1 up/up      169.254.1.6/23     cluster1-04   e0a     true
            cluster1-04_clus2 up/up      169.254.1.7/23     cluster1-04   e0a     false
8 entries were displayed.
cluster1::*>
----
====
. Vérifiez que le cluster fonctionne correctement :
+
`cluster show`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  -------
cluster1-01          true    true          false
cluster1-02          true    true          false
cluster1-03          true    true          true
cluster1-04          true    true          false
4 entries were displayed.
cluster1::*>
----
====
. Si ce n'est pas déjà fait, enregistrez une copie de la configuration actuelle du commutateur en copiant la sortie de la commande suivante dans un fichier texte :
+
`show running-config`

+
.. Enregistrez tous les ajouts personnalisés entre le courant `running-config` et le fichier RCF utilisé (comme une configuration SNMP pour votre organisation).
.. À partir de NX-OS 10.2, utilisez le `show diff running-config` commande à comparer avec le fichier RCF enregistré dans le bootflash.  Sinon, utilisez un outil de comparaison/différence tiers.


. Enregistrez les détails de configuration de base dans le `write_erase.cfg` fichier sur le bootflash.
+
[NOTE]
====
Assurez-vous de configurer les éléments suivants :

** Nom d'utilisateur et mot de passe
** Adresse IP de gestion
** Passerelle par défaut
** Nom du commutateur


====
+
`cs1# show run | i "username admin password" > bootflash:write_erase.cfg`

+
`cs1# show run | section "vrf context management" >> bootflash:write_erase.cfg`

+
`cs1# show run | section "interface mgmt0" >> bootflash:write_erase.cfg`

+
`cs1# show run | section "switchname" >> bootflash:write_erase.cfg`

. Lors de la mise à niveau vers la version 1.12 de RCF et les versions ultérieures, exécutez les commandes suivantes :
+
`cs1# echo "hardware access-list tcam region ing-racl 1024" >> bootflash:write_erase.cfg`

+
`cs1# echo "hardware access-list tcam region egr-racl 1024" >> bootflash:write_erase.cfg`

+
`cs1# echo "hardware access-list tcam region ing-l2-qos 1280" >> bootflash:write_erase.cfg`

+
Voir l'article de la base de connaissanceslink:https://kb.netapp.com/on-prem/Switches/Cisco-KBs/How_to_clear_configuration_on_a_Cisco_interconnect_switch_while_retaining_remote_connectivity["Comment effacer la configuration d'un commutateur d'interconnexion Cisco tout en conservant la connectivité à distance"^] pour plus de détails.

. Vérifiez que le `write_erase.cfg` le fichier est rempli comme prévu :
+
`*show file bootflash:write_erase.cfg*`

. Exécutez la commande write erase pour effacer la configuration actuellement enregistrée :
+
`cs1# *write erase*`

+
`Warning: This command will erase the startup-configuration.`

+
`Do you wish to proceed anyway? (y/n)  [n] *y*`

. Copiez la configuration de base précédemment enregistrée dans la configuration de démarrage.
+
`cs1# *copy bootflash:write_erase.cfg startup-config*`

. Redémarrer le commutateur :
+
`switch# *reload*`

+
`This command will reboot the system. (y/n)?  [n] *y*`

. Une fois que l'adresse IP de gestion est à nouveau accessible, connectez-vous au commutateur via SSH.
+
Vous devrez peut-être mettre à jour les entrées de fichier hôte liées aux clés SSH.

. Copiez la FCR dans le bootflash du commutateur cs1 à l'aide de l'un des protocoles de transfert suivants : FTP, TFTP, SFTP ou SCP.
+
Pour plus d'informations sur les commandes Cisco , consultez le guide approprié dans lelink:https://www.cisco.com/c/en/us/support/switches/nexus-9336c-fx2-switch/model.html#CommandReferences["Référence des commandes Cisco Nexus série 9000 NX-OS"^] guides.

+
Cet exemple montre que TFTP est utilisé pour copier une FCR sur le bootflash du commutateur cs1 :

+
[listing, subs="+quotes"]
----
cs1# *copy tftp: bootflash: vrf management*
Enter source filename: *Nexus_9336C_RCF_v1.6-Cluster-HA-Breakout.txt*
Enter hostname for the tftp server: *172.22.201.50*
Trying to connect to tftp server......Connection to Server Established.
TFTP get operation was successful
Copy complete, now saving to disk (please wait)...
----
. Appliquez le RCF préalablement téléchargé sur le bootflash.
+
Pour plus d'informations sur les commandes Cisco , consultez le guide approprié dans lelink:https://www.cisco.com/c/en/us/support/switches/nexus-9336c-fx2-switch/model.html#CommandReferences["Référence des commandes Cisco Nexus série 9000 NX-OS"^] .

+
Cet exemple montre le fichier RCF `Nexus_9336C_RCF_v1.6-Cluster-HA-Breakout.txt` en cours d'installation sur le commutateur cs1 :

+
[listing, subs="+quotes"]
----
cs1# *copy Nexus_9336C_RCF_v1.6-Cluster-HA-Breakout.txt running-config echo-commands*
----
+
[NOTE]
====
Assurez-vous de lire attentivement les sections *Notes d'installation*, *Notes importantes* et *bannière* de votre RCF.  Vous devez lire et suivre ces instructions pour garantir la configuration et le fonctionnement corrects du commutateur.

====
. Vérifiez que le fichier RCF est la version la plus récente correcte :
+
`show running-config`

+
Lorsque vous vérifiez que la sortie est correcte, vérifiez que les informations suivantes sont correctes :

+
** La bannière RCF
** Les paramètres du nœud et du port
** Personnalisations
+
Le résultat varie en fonction de la configuration de votre site. Vérifiez les paramètres des ports et reportez-vous aux notes de version pour voir si des modifications spécifiques à la FCR que vous avez installée.



. Réappliquez toutes les personnalisations précédentes à la configuration du commutateur. Reportez-vous link:cabling-considerations-9336c-fx2.html["Examinez les considérations relatives au câblage et à la configuration"]à pour plus de détails sur les modifications supplémentaires requises.
. Une fois que vous avez vérifié que les versions de RCF, les ajouts personnalisés et les paramètres de commutateur sont corrects, copiez le fichier running-config dans le fichier startup-config.
+
Pour plus d'informations sur les commandes Cisco , consultez le guide approprié dans lelink:https://www.cisco.com/c/en/us/support/switches/nexus-9336c-fx2-switch/model.html#CommandReferences["Référence des commandes Cisco Nexus série 9000 NX-OS"^] .

+
`cs1# copy running-config startup-config`

+
`[########################################] 100% Copy complete`

. Redémarrez le commutateur cs1. Vous pouvez ignorer les alertes « cluster switch Health Monitor » et les événements « cluster ports down » rapportés sur les nœuds lors du redémarrage du switch.
+
`cs1# *reload*`

+
`This command will reboot the system. (y/n)?  [n] *y*`

. Vérifier l'état de santé des ports du cluster sur le cluster.
+
.. Vérifier que les ports du cluster fonctionnent correctement sur tous les nœuds du cluster :
+
`network port show -role cluster`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -role cluster*

Node: cluster1-01
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-02
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-03
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false

Node: cluster1-04
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false
8 entries were displayed.
----
====
.. Vérifiez l'état du commutateur depuis le cluster.
+
`network device-discovery show -protocol cdp`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------- --------
cluster1-01/cdp
            e0a    cs1                       Ethernet1/7       N9K-C9336C
            e0d    cs2                       Ethernet1/7       N9K-C9336C
cluster01-2/cdp
            e0a    cs1                       Ethernet1/8       N9K-C9336C
            e0d    cs2                       Ethernet1/8       N9K-C9336C
cluster01-3/cdp
            e0a    cs1                       Ethernet1/1/1     N9K-C9336C
            e0b    cs2                       Ethernet1/1/1     N9K-C9336C
cluster1-04/cdp
            e0a    cs1                       Ethernet1/1/2     N9K-C9336C
            e0b    cs2                       Ethernet1/1/2     N9K-C9336C

cluster1::*> *system cluster-switch show -is-monitoring-enabled-operational true*
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- -----
cs1                         cluster-network    10.233.205.90    NX9-C9336C
     Serial Number: FOCXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(5)
    Version Source: CDP

cs2                         cluster-network    10.233.205.91    NX9-C9336C
     Serial Number: FOCXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(5)
    Version Source: CDP

2 entries were displayed.
----
Vous pouvez observer les valeurs de sortie suivantes sur la console des commutateurs cs1 en fonction de la version RCF précédemment chargée sur le commutateur :

[listing]
----
2020 Nov 17 16:07:18 cs1 %$ VDC-1 %$ %STP-2-UNBLOCK_CONSIST_PORT: Unblocking port port-channel1 on VLAN0092. Port consistency restored.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_PEER: Blocking port-channel1 on VLAN0001. Inconsistent peer vlan.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_LOCAL: Blocking port-channel1 on VLAN0092. Inconsistent local vlan.
----
====


. Vérifiez que le cluster fonctionne correctement :
+
`cluster show`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health   Eligibility   Epsilon
-------------------- -------- ------------- -------
cluster1-01          true     true          false
cluster1-02          true     true          false
cluster1-03          true     true          true
cluster1-04          true     true          false
4 entries were displayed.
cluster1::*>
----
====
. Répétez les étapes 1 à 19 sur le commutateur cs2.
. Activez la fonction de revert automatique sur les LIFs du cluster.
+
`cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert True*`





== Étape 3 : vérifiez la configuration du réseau et l'état du cluster

. Vérifiez que les ports de commutateur connectés aux ports de cluster sont *UP*.
+
`show interface brief`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show interface brief | grep up*
.
.
Eth1/1/1      1       eth  access up      none                    10G(D) --
Eth1/1/2      1       eth  access up      none                    10G(D) --
Eth1/7        1       eth  trunk  up      none                   100G(D) --
Eth1/8        1       eth  trunk  up      none                   100G(D) --
.
.
----
====
. Vérifier que les nœuds attendus sont toujours connectés :
+
`show cdp neighbors`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         133    H           FAS2980       e0a
node2              Eth1/2         133    H           FAS2980       e0a
cs1                Eth1/35        175    R S I s     N9K-C9336C    Eth1/35
cs1                Eth1/36        175    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4
----
====
. Vérifiez que les nœuds de cluster se trouvent dans leurs VLAN de cluster corrects à l'aide des commandes suivantes :
+
`show vlan brief`

+
`show interface trunk`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show vlan brief*

VLAN Name                             Status    Ports
---- -------------------------------- --------- -------------------------------
1    default                          active    Po1, Eth1/1, Eth1/2, Eth1/3
                                                Eth1/4, Eth1/5, Eth1/6, Eth1/7
                                                Eth1/8, Eth1/35, Eth1/36
                                                Eth1/9/1, Eth1/9/2, Eth1/9/3
                                                Eth1/9/4, Eth1/10/1, Eth1/10/2
                                                Eth1/10/3, Eth1/10/4
17   VLAN0017                         active    Eth1/1, Eth1/2, Eth1/3, Eth1/4
                                                Eth1/5, Eth1/6, Eth1/7, Eth1/8
                                                Eth1/9/1, Eth1/9/2, Eth1/9/3
                                                Eth1/9/4, Eth1/10/1, Eth1/10/2
                                                Eth1/10/3, Eth1/10/4
18   VLAN0018                         active    Eth1/1, Eth1/2, Eth1/3, Eth1/4
                                                Eth1/5, Eth1/6, Eth1/7, Eth1/8
                                                Eth1/9/1, Eth1/9/2, Eth1/9/3
                                                Eth1/9/4, Eth1/10/1, Eth1/10/2
                                                Eth1/10/3, Eth1/10/4
31   VLAN0031                         active    Eth1/11, Eth1/12, Eth1/13
                                                Eth1/14, Eth1/15, Eth1/16
                                                Eth1/17, Eth1/18, Eth1/19
                                                Eth1/20, Eth1/21, Eth1/22
32   VLAN0032                         active    Eth1/23, Eth1/24, Eth1/25
                                                Eth1/26, Eth1/27, Eth1/28
                                                Eth1/29, Eth1/30, Eth1/31
                                                Eth1/32, Eth1/33, Eth1/34
33   VLAN0033                         active    Eth1/11, Eth1/12, Eth1/13
                                                Eth1/14, Eth1/15, Eth1/16
                                                Eth1/17, Eth1/18, Eth1/19
                                                Eth1/20, Eth1/21, Eth1/22
34   VLAN0034                         active    Eth1/23, Eth1/24, Eth1/25
                                                Eth1/26, Eth1/27, Eth1/28
                                                Eth1/29, Eth1/30, Eth1/31
                                                Eth1/32, Eth1/33, Eth1/34

cs1# *show interface trunk*

-----------------------------------------------------
Port          Native  Status        Port
              Vlan                  Channel
-----------------------------------------------------
Eth1/1        1       trunking      --
Eth1/2        1       trunking      --
Eth1/3        1       trunking      --
Eth1/4        1       trunking      --
Eth1/5        1       trunking      --
Eth1/6        1       trunking      --
Eth1/7        1       trunking      --
Eth1/8        1       trunking      --
Eth1/9/1      1       trunking      --
Eth1/9/2      1       trunking      --
Eth1/9/3      1       trunking      --
Eth1/9/4      1       trunking      --
Eth1/10/1     1       trunking      --
Eth1/10/2     1       trunking      --
Eth1/10/3     1       trunking      --
Eth1/10/4     1       trunking      --
Eth1/11       33      trunking      --
Eth1/12       33      trunking      --
Eth1/13       33      trunking      --
Eth1/14       33      trunking      --
Eth1/15       33      trunking      --
Eth1/16       33      trunking      --
Eth1/17       33      trunking      --
Eth1/18       33      trunking      --
Eth1/19       33      trunking      --
Eth1/20       33      trunking      --
Eth1/21       33      trunking      --
Eth1/22       33      trunking      --
Eth1/23       34      trunking      --
Eth1/24       34      trunking      --
Eth1/25       34      trunking      --
Eth1/26       34      trunking      --
Eth1/27       34      trunking      --
Eth1/28       34      trunking      --
Eth1/29       34      trunking      --
Eth1/30       34      trunking      --
Eth1/31       34      trunking      --
Eth1/32       34      trunking      --
Eth1/33       34      trunking      --
Eth1/34       34      trunking      --
Eth1/35       1       trnk-bndl     Po1
Eth1/36       1       trnk-bndl     Po1
Po1           1       trunking      --

------------------------------------------------------
Port          Vlans Allowed on Trunk
------------------------------------------------------
Eth1/1        1,17-18
Eth1/2        1,17-18
Eth1/3        1,17-18
Eth1/4        1,17-18
Eth1/5        1,17-18
Eth1/6        1,17-18
Eth1/7        1,17-18
Eth1/8        1,17-18
Eth1/9/1      1,17-18
Eth1/9/2      1,17-18
Eth1/9/3      1,17-18
Eth1/9/4      1,17-18
Eth1/10/1     1,17-18
Eth1/10/2     1,17-18
Eth1/10/3     1,17-18
Eth1/10/4     1,17-18
Eth1/11       31,33
Eth1/12       31,33
Eth1/13       31,33
Eth1/14       31,33
Eth1/15       31,33
Eth1/16       31,33
Eth1/17       31,33
Eth1/18       31,33
Eth1/19       31,33
Eth1/20       31,33
Eth1/21       31,33
Eth1/22       31,33
Eth1/23       32,34
Eth1/24       32,34
Eth1/25       32,34
Eth1/26       32,34
Eth1/27       32,34
Eth1/28       32,34
Eth1/29       32,34
Eth1/30       32,34
Eth1/31       32,34
Eth1/32       32,34
Eth1/33       32,34
Eth1/34       32,34
Eth1/35       1
Eth1/36       1
Po1           1
..
..
..
..
..
----
====
+

NOTE: Pour plus de détails sur l'utilisation des ports et des VLAN, reportez-vous à la section bannière et remarques importantes de votre FCR.

. Vérifier que l'ISL entre cs1 et cs2 est fonctionnel :
+
`show port-channel summary`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/35(P)        Eth1/36(P)
cs1#
----
====
. Vérifier que les LIFs du cluster ont rétabli leur port de base :
+
`network interface show -role cluster`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical            Status     Network            Current             Current Is
Vserver     Interface          Admin/Oper Address/Mask       Node                Port    Home
----------- ------------------ ---------- ------------------ ------------------- ------- ----
Cluster
            cluster1-01_clus1  up/up      169.254.3.4/23     cluster1-01         e0d     true
            cluster1-01_clus2  up/up      169.254.3.5/23     cluster1-01         e0d     true
            cluster1-02_clus1  up/up      169.254.3.8/23     cluster1-02         e0d     true
            cluster1-02_clus2  up/up      169.254.3.9/23     cluster1-02         e0d     true
            cluster1-03_clus1  up/up      169.254.1.3/23     cluster1-03         e0b     true
            cluster1-03_clus2  up/up      169.254.1.1/23     cluster1-03         e0b     true
            cluster1-04_clus1  up/up      169.254.1.6/23     cluster1-04         e0b     true
            cluster1-04_clus2  up/up      169.254.1.7/23     cluster1-04         e0b     true
8 entries were displayed.
cluster1::*>
----
====
+
Si une LIF de cluster n'est pas retournée sur son port de rattachement, la restaurer manuellement depuis le nœud local :

+
`network interface revert -vserver vserver_name -lif lif_name`

. Vérifiez que le cluster fonctionne correctement :
+
`cluster show`

+
.Montrer l'exemple
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------- -------
cluster1-01          true    true          false
cluster1-02          true    true          false
cluster1-03          true    true          true
cluster1-04          true    true          false
4 entries were displayed.
cluster1::*>
----
====
. Vérifiez la connectivité des interfaces de cluster distantes :


[role="tabbed-block"]
====
.ONTAP 9.9.1 et versions ultérieures
--
Vous pouvez utiliser le `network interface check cluster-connectivity` pour lancer un contrôle d'accessibilité pour la connectivité du cluster, puis afficher les détails :

`network interface check cluster-connectivity start` et `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*REMARQUE :* attendez un certain nombre de secondes avant d'exécuter `show` la commande pour afficher les détails.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source               Destination         Packet
Node   Date                       LIF                  LIF                 Loss
------ -------------------------- -------------------- ------------------- -----------
node1
       3/5/2022 19:21:18 -06:00   cluster1-01_clus2    cluster1-02-clus1   none
       3/5/2022 19:21:20 -06:00   cluster1-01_clus2    cluster1-02_clus2   none
node2
       3/5/2022 19:21:18 -06:00   cluster1-02_clus2    cluster1-01_clus1   none
       3/5/2022 19:21:20 -06:00   cluster1-02_clus2    cluster1-01_clus2   none
----
--
.Toutes les versions de ONTAP
--
Pour toutes les versions de ONTAP, vous pouvez également utiliser `cluster ping-cluster -node <name>` pour vérifier la connectivité :

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is cluster1-03
Getting addresses from network interface table...
Cluster cluster1-03_clus1 169.254.1.3 cluster1-03 e0a
Cluster cluster1-03_clus2 169.254.1.1 cluster1-03 e0b
Cluster cluster1-04_clus1 169.254.1.6 cluster1-04 e0a
Cluster cluster1-04_clus2 169.254.1.7 cluster1-04 e0b
Cluster cluster1-01_clus1 169.254.3.4 cluster1-01 e0a
Cluster cluster1-01_clus2 169.254.3.5 cluster1-01 e0d
Cluster cluster1-02_clus1 169.254.3.8 cluster1-02 e0a
Cluster cluster1-02_clus2 169.254.3.9 cluster1-02 e0d
Local = 169.254.1.3 169.254.1.1
Remote = 169.254.1.6 169.254.1.7 169.254.3.4 169.254.3.5 169.254.3.8 169.254.3.9
Cluster Vserver Id = 4294967293
Ping status:
............
Basic connectivity succeeds on 12 path(s)
Basic connectivity fails on 0 path(s)
................................................
Detected 9000 byte MTU on 12 path(s):
    Local 169.254.1.3 to Remote 169.254.1.6
    Local 169.254.1.3 to Remote 169.254.1.7
    Local 169.254.1.3 to Remote 169.254.3.4
    Local 169.254.1.3 to Remote 169.254.3.5
    Local 169.254.1.3 to Remote 169.254.3.8
    Local 169.254.1.3 to Remote 169.254.3.9
    Local 169.254.1.1 to Remote 169.254.1.6
    Local 169.254.1.1 to Remote 169.254.1.7
    Local 169.254.1.1 to Remote 169.254.3.4
    Local 169.254.1.1 to Remote 169.254.3.5
    Local 169.254.1.1 to Remote 169.254.3.8
    Local 169.254.1.1 to Remote 169.254.3.9
Larger than PMTU communication succeeds on 12 path(s)
RPC status:
6 paths up, 0 paths down (tcp check)
6 paths up, 0 paths down (udp check)
----
--
====
.Et la suite ?
Après avoir mis à niveau votre RCF, vouslink:configure-ssh-keys.html["vérifier la configuration SSH"] .
